{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path integration\n",
    "\n",
    "**Author:** Sibo Wang-Chen\n",
    "\n",
    "**Note:** The code presented in this notebook has been simplified and restructured for display in a notebook format. A more complete and better structured implementation can be found in the [examples folder of the FlyGym repository on GitHub](https://github.com/NeLy-EPFL/flygym/tree/main/flygym/examples/).\n",
    "\n",
    "**Summary:** In this tutorial, we will show how the position and heading of the animal can be estimated by integrating mechanosensory signals, a process known as path integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the previous tutorials, we have demonstrated how brain-level processes can drive the motor system via _descending control_. _Ascending_ motor signals are a complement to descending information as they convey information, often mechanosensory in nature, back to the brain. Ascending signals are predicted to inform brain-level action selection, motor planning, and sensory contextualization (see [Chen et al., 2023](https://doi.org/10.1038/s41593-023-01281-z)). In this tutorial and the next, we will demonstrate how incorporating ascending motor feedback signals allows us to model behaviors that are critical to the animal's survival and functioning.\n",
    "\n",
    "Animals, including flies, estimate their own orientation and distance traveled (\"odometry\") to perform path integration when navigating the world. A superb example of path integration was demonstrated in the desert ant _Cataglyphis fortis_ (see [review by Wolf, 2011](https://doi.org/10.1242/jeb.038570)). While the ant takes an exploratory outbound path in search of a food source, it can return to the nest in a straight line. Furthermore, if the experimenter moves the ant to a different location upon finding the food, the ant still takes the \"correct\" path back to the nest, but starting from the location where it has been \"air dropped\" (as shown below). These results show that the ant must be using idiothetic cues, rather than sensory input, to navigate — similar to how sailors used to navigate featureless oceans by \"dead reckoning.\"\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/NeLy-EPFL/_media/blob/main/flygym/path_integration/pathint_schematic.png?raw=true\" alt=\"pathint_schematic.png\" width=\"300\"/>\n",
    "</p>\n",
    "\n",
    "The fly _Drosophila melanogaster_ also performs path integration, especially when navigating to find food sources (see [Kim & Dickinson, 2017](https://doi.org/10.1016/j.cub.2017.06.026), [Behbahani et al., 2021](https://doi.org/10.1016/j.cub.2021.08.006)). While the source of the idiothetic cues are unknown, they may, in principle, be derived using ascending proprioceptive and tactile signals from the legs and motor system. As a demonstration, we will attempt to estimate the changes in the fly's orientation (shown below in green) and displacement (shown below in purple) based on proprioceptive and tactile information. By integrating these changes over time, we aim to reconstruct the path of the fly in space (right).\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/NeLy-EPFL/_media/blob/main/flygym/path_integration/pathint_integration.png?raw=true\" alt=\"pathint_integration.png\" width=\"600\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The algorithm\n",
    "\n",
    "Having hand-waved at how we aim to accomplish path integration, we will try to make our proposed algorithm more precise. We can partition our task into two sub-problems:\n",
    "\n",
    "1. How do we predict the changes in heading and forward displacement from proprioception and tactile information?\n",
    "2. With these estimated \"deltas\" in heading and forward displacement, how do we integrate them to find the position?\n",
    "\n",
    "The first question can be tackled in the following way: for each leg, we accumulate stride lengths by computing the forward translation of the leg tip relative to the thorax when the leg is pushing. Proprioception gives us the positions of the leg tips; tactile sensing tells us whether the leg was in contact with the ground, which we use as a proxy to detect leg pushing. Together, proprioception and tactile sensing allow us to calculate the stride lengths. Then, we compute the differences and sums of the left and right total stride lengths for each pair of legs over a small time window. These left-right differences and their sums are then used to predict the change in heading and forward displacement respectively. We will use a simple linear regression model for this purpose.\n",
    "\n",
    "However, we have glossed over one important detail: to predict the change in heading and forward displacement, we need the _changes_ in the cumulated left-right differences and sums. But to calculate these changes, we must first define a _time scale_. This underlies our solution to the second part of the problem. We record the cumulated left-right differences and sums at every point in time during the walking simulation. Then, for every time $t$, can compute the changes in the left-right differences and sums from time $t-\\tau$ ($\\tau$ being the time scale) to time $t$. If we use these \"delta differences\" and \"delta sums\" to predict \"delta heading\" and \"delta forward displacement,\" we can get the changes in heading and forward displacement in the same time scale. Therefore, we can simply re-normalize the predicted values by the time scale, and integrate the position in 2D. This process can be shown in the following schematic:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/NeLy-EPFL/_media/blob/main/flygym/path_integration/pathint_prediction.png?raw=true\" alt=\"pathint_prediction.png\" width=\"400\"/>\n",
    "</p>\n",
    "\n",
    "In the next sections, we will test this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting walking data\n",
    "\n",
    "To train the models, we first need to collect data where the fly walks in a trajectory similar to foraging desert ants. To this end, we will construct a scenario in which the fly model performs random exploration of a featureless environment. Here, the fly alternates between forward walking and in-place turning. We will control turning in a Poisson process with a rate $\\lambda_\\text{turn}=2\\text{ s}^{-1}$. This turning rate is quite high compared to the range of typical fly behavior. This is to deliberately make path integration more difficult. When the fly executes a turn, we will apply a fixed asymmetrical descending drive of $[{\\rm DN}_\\text{inner}, {\\rm DN}_\\text{outer}]$ which has the following values:\n",
    "\n",
    "- $[{\\rm DN}_\\text{inner}, {\\rm DN}_\\text{outer}] = [-0.2, 1.0]$ for the tripod and tetrapod gaits\n",
    "- $[{\\rm DN}_\\text{inner}, {\\rm DN}_\\text{outer}] = [0.4, 1.0]$ for the wave gait\n",
    "\n",
    "These choices lead to qualitatively similar turning across gait types. The direction of the turn is chosen at random. We will sample the duration of the turn (and therefore the angle turned) from a normal distribution $\\mathcal{N}(0.4\\text{ s}, 0.1\\text{ s})$. The fly receives no visual information — akin to navigating in the dark. We will use the [hybrid turning controller](https://neuromechfly.org/tutorials/turning.html#implementing-the-hybridturningcontroller-class), but with the correction amounts set to 0 for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from flygym import Fly, Camera\n",
    "from flygym.preprogrammed import get_cpg_biases\n",
    "from flygym.examples.path_integration.arena import PathIntegrationArenaFlat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the discrete walking states as an `Enum` class (see [this tutorial](https://docs.python.org/3/howto/enum.html) for more information on Enum if you are not familiar with it, but this is not required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class WalkingState(Enum):\n",
    "    FORWARD = 0\n",
    "    TURN_LEFT = 1\n",
    "    TURN_RIGHT = 2\n",
    "    STOP = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a random exploration controller that controls the switch between straight walking and turning in a Poisson process, as discussed above. We will implement this controller as a class with a `.step` method, which returns the next state and the corresponding descending drives. Note that this controller is detached from the physics simulation — it only tells us which walking state the simulated fly _should_ be in in the next step.\n",
    "\n",
    "In a Poisson process, the cumulative distribution function of the exponential distribution is\n",
    "$$ F(x) = 1 - e^{-\\lambda x} $$\n",
    "\n",
    "Therefore, the probability that the transition will happen within the next $\\Delta t$ seconds is\n",
    "$$ P(T_{\\rm turn} \\leq {\\rm d} t) = 1 - e^{-\\lambda \\Delta t} $$\n",
    "where $\\Delta t$ is the simulation time step and $T_{\\rm turn}$ is the time until the next transition to turning. As a result, we will change the state to turning if and only if a scalar uniformly randomly sampled from 0 to 1 is greater than $e^{-\\lambda \\Delta t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class RandomExplorationController:\n",
    "    \"\"\"This controller drives a random exploration: the fly transitions\n",
    "    between forward walking and turning in a Poisson process. When the fly\n",
    "    turns, the turn direction is chosen randomly and the turn duration is\n",
    "    drawn from a normal distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dt: float,\n",
    "        forward_dn_drive: tuple[float, float] = (1.0, 1.0),\n",
    "        left_turn_dn_drive: tuple[float, float] = (-0.4, 1.2),\n",
    "        right_turn_dn_drive: tuple[float, float] = (1.2, -0.4),\n",
    "        turn_duration_mean: float = 0.4,\n",
    "        turn_duration_std: float = 0.1,\n",
    "        lambda_turn: float = 1.0,\n",
    "        seed: int = 0,\n",
    "        init_time: float = 0.1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dt : float\n",
    "            Time step of the simulation.\n",
    "        forward_dn_drive : tuple[float, float], optional\n",
    "            DN drives for forward walking, by default (1.0, 1.0).\n",
    "        left_turn_dn_drive : tuple[float, float], optional\n",
    "            DN drives for turning left, by default (-0.4, 1.2).\n",
    "        right_turn_dn_drive : tuple[float, float], optional\n",
    "            DN drives for turning right, by default (1.2, -0.4).\n",
    "        turn_duration_mean : float, optional\n",
    "            Mean of the turn duration distribution in seconds, by default\n",
    "            0.4.\n",
    "        turn_duration_std : float, optional\n",
    "            Standard deviation of the turn duration distribution in\n",
    "            seconds, by default 0.1.\n",
    "        lambda_turn : float, optional\n",
    "            Rate of the Poisson process for turning, by default 1.0.\n",
    "        seed : int, optional\n",
    "            Random seed, by default 0.\n",
    "        init_time : float, optional\n",
    "            Initial time, in seconds, during which the fly walks straight,\n",
    "            by default 0.1.\n",
    "        \"\"\"\n",
    "        self.random_state = np.random.RandomState(seed)\n",
    "        self.dt = dt\n",
    "        self.init_time = init_time\n",
    "        self.curr_time = 0.0\n",
    "        self.curr_state: WalkingState = WalkingState.FORWARD\n",
    "        self._curr_turn_duration: Union[None, float] = None\n",
    "\n",
    "        # DN drives\n",
    "        self.dn_drives = {\n",
    "            WalkingState.FORWARD: np.array(forward_dn_drive),\n",
    "            WalkingState.TURN_LEFT: np.array(left_turn_dn_drive),\n",
    "            WalkingState.TURN_RIGHT: np.array(right_turn_dn_drive),\n",
    "        }\n",
    "\n",
    "        # Turning related parameters\n",
    "        self.turn_duration_mean = turn_duration_mean\n",
    "        self.turn_duration_std = turn_duration_std\n",
    "        self.lambda_turn = lambda_turn\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Update the fly's walking state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        WalkingState\n",
    "            The next state of the fly.\n",
    "        tuple[float, float]\n",
    "            The next DN drives.\n",
    "        \"\"\"\n",
    "        # Upon spawning, just walk straight for a bit (init_time) for things to settle\n",
    "        if self.curr_time < self.init_time:\n",
    "            self.curr_time += self.dt\n",
    "            return WalkingState.FORWARD, self.dn_drives[WalkingState.FORWARD]\n",
    "\n",
    "        # Forward -> turn transition\n",
    "        if self.curr_state == WalkingState.FORWARD:\n",
    "            # exponential function defining how likely it is that transition will NOT\n",
    "            # happen in the next time step\n",
    "            p_nochange = np.exp(-self.lambda_turn * self.dt)\n",
    "            if self.random_state.rand() > p_nochange:\n",
    "                # decide turn duration and direction\n",
    "                self._curr_turn_duration = self.random_state.normal(\n",
    "                    self.turn_duration_mean, self.turn_duration_std\n",
    "                )\n",
    "                self.curr_state = self.random_state.choice(\n",
    "                    [WalkingState.TURN_LEFT, WalkingState.TURN_RIGHT]\n",
    "                )\n",
    "                self.curr_state_start_time = self.curr_time\n",
    "\n",
    "        # Turn -> forward transition\n",
    "        if self.curr_state in (WalkingState.TURN_LEFT, WalkingState.TURN_RIGHT):\n",
    "            if self.curr_time - self.curr_state_start_time > self._curr_turn_duration:\n",
    "                self.curr_state = WalkingState.FORWARD\n",
    "                self.curr_state_start_time = self.curr_time\n",
    "\n",
    "        self.curr_time += self.dt\n",
    "        return self.curr_state, self.dn_drives[self.curr_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, we will use the hybrid turning controller that we have implemented previously. However, still missing from the `HybridTurningController` class is the ability to find the coordinates of the leg tips (or any point at all) in the reference frame of the fly. We will now extend `HybridTurningController` to a new `PathIntegrationController` class that has a `.absolute_to_relative_pos` method that does exactly this. We will add a `\"stride_diff_unmasked\"` key to the observation that records how much the leg tips have shifted from the previous simulation time step. More precisely, for each leg,\n",
    "\n",
    "$$\n",
    "\\text{stride\\_diff\\_unmasked}[i] =\n",
    "    \\text{rel\\_leg\\_tip\\_pos}[i] - \\text{rel\\_leg\\_tip\\_pos}[i - 1]\n",
    "$$\n",
    "\n",
    "where $\\text{rel\\_leg\\_tip\\_pos}[i]$ is the position of the tip of this leg at the $i$-th step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.examples.locomotion import HybridTurningController\n",
    "\n",
    "\n",
    "class PathIntegrationController(HybridTurningController):\n",
    "    \"\"\"\n",
    "    A wrapper of ``HybridTurningController`` that records variables that\n",
    "    are used to perform path integration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._last_end_effector_pos: Union[None, np.ndarray] = None\n",
    "        self.total_stride_lengths_hist = []\n",
    "        self.heading_estimate_hist = []\n",
    "        self.pos_estimate_hist = []\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Same as ``HybridTurningController.step``, but also records the\n",
    "        stride for each leg (i.e., how much the leg tip has moved in the\n",
    "        fly's egocentric frame since the last step) in the observation\n",
    "        space under the key \"stride_diff_unmasked\". Note that this\n",
    "        calculation does not take into account whether the \"stride\" is\n",
    "        actually made during a power stroke (i.e., stance phase); it only\n",
    "        reports the change in end effector positions in an \"unmasked\"\n",
    "        manner. The user should post-process it using the contact mask as a\n",
    "        part of the model.\n",
    "        \"\"\"\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "\n",
    "        # Calculate stride since last step for each leg\n",
    "        ee_pos_rel = self.absolute_to_relative_pos(\n",
    "            obs[\"end_effectors\"][:, :2], obs[\"fly\"][0, :2], obs[\"fly_orientation\"][:2]\n",
    "        )\n",
    "        if self._last_end_effector_pos is None:\n",
    "            ee_diff = np.zeros_like(ee_pos_rel)\n",
    "        else:\n",
    "            ee_diff = ee_pos_rel - self._last_end_effector_pos\n",
    "        self._last_end_effector_pos = ee_pos_rel\n",
    "        obs[\"stride_diff_unmasked\"] = ee_diff\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    @staticmethod\n",
    "    def absolute_to_relative_pos(\n",
    "        pos: np.ndarray, base_pos: np.ndarray, heading: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        rel_pos = pos - base_pos\n",
    "        heading = heading / np.linalg.norm(heading)\n",
    "        angle = np.arctan2(heading[1], heading[0])\n",
    "        rot_matrix = np.array(\n",
    "            [[np.cos(-angle), -np.sin(-angle)], [np.sin(-angle), np.cos(-angle)]]\n",
    "        )\n",
    "        pos_rotated = np.dot(rel_pos, rot_matrix.T)\n",
    "        return pos_rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to write a `run_simulation` function that interfaces the state switching controller with the physics-embedded NeuroMechFly simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    seed: int = 0,\n",
    "    running_time: float = 20.0,\n",
    "    gait: str = \"tripod\",\n",
    "    output_dir: Optional[Path] = None,\n",
    "):\n",
    "    contact_sensor_placements = [\n",
    "        f\"{leg}{segment}\"\n",
    "        for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "        for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "    ]\n",
    "\n",
    "    fly = Fly(\n",
    "        enable_adhesion=True,\n",
    "        draw_adhesion=True,\n",
    "        contact_sensor_placements=contact_sensor_placements,\n",
    "        spawn_pos=(0, 0, 0.25),\n",
    "    )\n",
    "\n",
    "    arena = PathIntegrationArenaFlat()\n",
    "\n",
    "    cam_params = {\n",
    "        \"mode\":\"fixed\",\n",
    "        \"pos\": (0, 0, 150),\n",
    "        \"euler\":(0, 0, 0),\n",
    "        \"fovy\":60\n",
    "        }\n",
    "    \n",
    "    cam = Camera(\n",
    "        attachment_point=arena.root_element.worldbody,\n",
    "        camera_name=\"birdeye_cam\",\n",
    "        timestamp_text = False,\n",
    "        camera_parameters=cam_params\n",
    "    )\n",
    "    \n",
    "    sim = PathIntegrationController(\n",
    "        phase_biases=get_cpg_biases(gait),\n",
    "        fly=fly,\n",
    "        arena=arena,\n",
    "        cameras=[cam],\n",
    "        timestep=1e-4,\n",
    "        correction_rates={\"retraction\": (0, 0), \"stumbling\": (0, 0)},\n",
    "    )\n",
    "\n",
    "    random_exploration_controller = RandomExplorationController(\n",
    "        dt=sim.timestep,\n",
    "        lambda_turn=2,\n",
    "        seed=seed,\n",
    "        forward_dn_drive=(1.0, 1.0),\n",
    "        left_turn_dn_drive=(0.2, 1.0) if gait == \"wave\" else (-0.2, 1.0),\n",
    "        right_turn_dn_drive=(1.0, 0.2) if gait == \"wave\" else (1.0, -0.2),\n",
    "    )\n",
    "\n",
    "    obs, info = sim.reset(0)\n",
    "    obs_hist, info_hist, action_hist = [], [], []\n",
    "    _real_heading_buffer = []\n",
    "    for i in trange(int(running_time / sim.timestep)):\n",
    "        walking_state, dn_drive = random_exploration_controller.step()\n",
    "        action_hist.append(dn_drive)\n",
    "        obs, reward, terminated, truncated, info = sim.step(dn_drive)\n",
    "\n",
    "        # Get real heading\n",
    "        orientation_x, orientation_y = obs[\"fly_orientation\"][:2]\n",
    "        real_heading = np.arctan2(orientation_y, orientation_x)\n",
    "        _real_heading_buffer.append(real_heading)\n",
    "\n",
    "        obs_hist.append(obs)\n",
    "        info_hist.append(info)\n",
    "\n",
    "    # Save data if output_dir is provided\n",
    "    if output_dir is not None:\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(output_dir / \"sim_data.pkl\", \"wb\") as f:\n",
    "            data = {\n",
    "                \"obs_hist\": obs_hist,\n",
    "                \"info_hist\": info_hist,\n",
    "                \"action_hist\": action_hist,\n",
    "            }\n",
    "            pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a 1-second simulation and plot the fly's trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"outputs/path_integration/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_simulation(seed=0, running_time=1.0, gait=\"tripod\", output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(output_dir / \"sim_data.pkl\", \"rb\") as f:\n",
    "    sim_data = pickle.load(f)\n",
    "\n",
    "trajectory = np.array([obs[\"fly\"][0, :2] for obs in sim_data[\"obs_hist\"]])\n",
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "ax.plot(trajectory[:, 0], trajectory[:, 1], label=\"Trajectory\")\n",
    "ax.plot([0], [0], \"ko\", label=\"Origin\")\n",
    "ax.legend()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"x position (mm)\")\n",
    "ax.set_ylabel(\"y position (mm)\")\n",
    "fig.savefig(output_dir / \"trajectory_sample_1s.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the recorded shifts in leg tip positions relative to the fly's thorax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_diff_unmasked = np.array(\n",
    "    [x[\"stride_diff_unmasked\"] for x in sim_data[\"obs_hist\"]]\n",
    ")\n",
    "t_grid = np.arange(stride_diff_unmasked.shape[0]) * 1e-4\n",
    "fig, axs = plt.subplots(3, 1, figsize=(5, 5), tight_layout=True, sharex=True)\n",
    "for i, leg_pair in enumerate([\"Front\", \"Middle\", \"Hind\"]):\n",
    "    ax = axs[i]\n",
    "    ax.axhline(0, color=\"k\", linestyle=\"-\", lw=1)\n",
    "    left_ts = stride_diff_unmasked[:, i, :]\n",
    "    right_ts = stride_diff_unmasked[:, i + 3, :]\n",
    "    ax.plot(t_grid, left_ts[:, 0], lw=1, label=\"Left\")\n",
    "    ax.plot(t_grid, right_ts[:, 0], lw=1, label=\"Right\")\n",
    "    ax.set_ylim(-0.02, 0.02)\n",
    "    if i == 0:\n",
    "        ax.legend(ncols=2, loc=\"lower right\")\n",
    "    if i == 2:\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"x offset (mm)\")\n",
    "    ax.set_title(f\"{leg_pair} legs\")\n",
    "    fig.savefig(output_dir / \"ee_shift_1s.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the time series of the change in the x position (along the anterior-posterior axis) of the leg tips from the previous time step. Note that the values can be both positive and negative. This is because we are simply reporting the shift in the claw positions without taking into account whether the legs are in stance or swing yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NeuroMechFly v2 paper, we ran 15 trials with different random seeds for each of the three gaits: tripod gait, tetrapod gait, and wave gait. Each trial was 20 seconds long. In this tutorial, we will use only 5 trials for the tripod gait. We have uploaded the simulation data of all trials to a SFTP server. Instead of running these simulations yourself (which would take roughly 20 minutes on a machine with 5+ cores), you can simply download the data by running the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. We are working with our IT team to set up a gateway to share these data publicly\n",
    "# in a secure manner. We aim to update this by the end of June, 2024. Please reach out\n",
    "# to us by email in the meantime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_data_dir = (\n",
    "    Path.home() / \"Data/flygym_demo_data/path_integration/random_exploration/\")\n",
    "if not exploration_data_dir.is_dir():\n",
    "    raise FileNotFoundError(\n",
    "        \"Pregenerated simulation data not found. Please download it from TODO.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"[OK] Pregenerated simulation data found. Ready to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting input and target variables from simulation data\n",
    "\n",
    "Let's start by loading basic information — time series of end effector positions, ground contact forces, descending drives, fly orientation, and fly position — from the simulation data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def load_trial_data(trial_dir: Path) -> dict[str, np.ndarray]:\n",
    "    \"\"\"Load simulation data from trial.\n",
    "    The difference between ``load_trial_data`` and ``extract_variables`` is\n",
    "    that the former loads the raw data from the trial (i.e., physics\n",
    "    simulation). The latter extracts variables from these raw data subject\n",
    "    to additional parameters such as time scale. For each trial, we only\n",
    "    call ``load_trial_data`` once, but we may call ``extract_variables``\n",
    "    multiple times with different parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_dir : Path\n",
    "        Path to the directory containing the trial data saved in\n",
    "        ``exploration.run_simulation``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, np.ndarray]\n",
    "        Dictionary containing the following keys, each mapping to a time\n",
    "        series saved as a numpy array:\n",
    "        * \"end_effector_pos_diff\": End effector positions.\n",
    "        * \"contact_force\": Contact forces.\n",
    "        * \"dn_drive\": DN drives.\n",
    "        * \"fly_orientation_xy\": Fly orientation in the form of a unit vector\n",
    "          on the xy plane.\n",
    "        * \"fly_orientation_angle\": Fly orientation in the form of an angle\n",
    "          in radians.\n",
    "        * \"fly_pos\": Fly position.\n",
    "    \"\"\"\n",
    "    with open(trial_dir / \"sim_data.pkl\", \"rb\") as f:\n",
    "        sim_data = pickle.load(f)\n",
    "    obs_hist = sim_data[\"obs_hist\"]\n",
    "\n",
    "    # End effector positions\n",
    "    end_effector_pos_diff = np.array(\n",
    "        [obs[\"stride_diff_unmasked\"] for obs in obs_hist], dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Contact forces\n",
    "    contact_force_ts = np.array(\n",
    "        [obs[\"contact_forces\"] for obs in obs_hist], dtype=np.float32\n",
    "    )\n",
    "    contact_force_ts = np.linalg.norm(contact_force_ts, axis=2)  # calc force magnitude\n",
    "    contact_force_ts = contact_force_ts.reshape(-1, 6, 6).sum(axis=2)  # total per leg\n",
    "\n",
    "    # Fly position\n",
    "    fly_pos_ts = np.array([obs[\"fly\"][0, :2] for obs in obs_hist], dtype=np.float32)\n",
    "\n",
    "    # Heading\n",
    "    fly_orientation_xy = np.array(\n",
    "        [obs[\"fly_orientation\"][:2] for obs in obs_hist], dtype=np.float32\n",
    "    )\n",
    "    fly_orientation_angle = np.arctan2(\n",
    "        fly_orientation_xy[:, 1], fly_orientation_xy[:, 0]\n",
    "    )\n",
    "\n",
    "    # Clear RAM right away manually to avoid memory fragmentation\n",
    "    del sim_data\n",
    "    gc.collect()\n",
    "\n",
    "    return {\n",
    "        \"end_effector_pos_diff\": end_effector_pos_diff.astype(np.float32),\n",
    "        \"contact_force\": contact_force_ts.astype(np.float32),\n",
    "        \"fly_orientation_xy\": fly_orientation_xy.astype(np.float32),\n",
    "        \"fly_orientation_angle\": fly_orientation_angle.astype(np.float32),\n",
    "        \"fly_pos\": fly_pos_ts.astype(np.float32),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = []\n",
    "num_trials = 5\n",
    "for seed in range(num_trials):\n",
    "    print(f\"Loading trial {seed + 1} of {num_trials}...\")\n",
    "    trial_dir = exploration_data_dir / f\"seed={seed}_gait=tripod\"\n",
    "    data = load_trial_data(trial_dir)\n",
    "    trial_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform some sanity tests on the data. As before, we can visualize the per-step change in end effector (leg tip) positions over 1 second of simulation, but this time in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trial_data[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), tight_layout=True)\n",
    "for i, leg_pair in enumerate([\"Front\", \"Middle\", \"Hind\"]):\n",
    "    ax = axs[i]\n",
    "    ax.axvline(0, color=\"k\", linestyle=\"--\", lw=1)\n",
    "    ax.axhline(0, color=\"k\", linestyle=\"--\", lw=1)\n",
    "    ax.plot(\n",
    "        data[\"end_effector_pos_diff\"][10000:20000, i, 0],\n",
    "        data[\"end_effector_pos_diff\"][10000:20000, i, 1],\n",
    "        lw=1,\n",
    "        label=\"Left\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        data[\"end_effector_pos_diff\"][10000:20000, i + 3, 0],\n",
    "        data[\"end_effector_pos_diff\"][10000:20000, i + 3, 1],\n",
    "        lw=1,\n",
    "        label=\"Right\",\n",
    "    )\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-0.02, 0.02)\n",
    "    ax.set_ylim(-0.02, 0.02)\n",
    "    ax.set_title(f\"{leg_pair} leg tips\")\n",
    "    if i == 0:\n",
    "        ax.set_xlabel(\"x offset (mm)\")\n",
    "        ax.set_ylabel(\"y offset (mm)\")\n",
    "        ax.legend(ncols=2, loc=\"lower center\")\n",
    "fig.savefig(output_dir / \"ee_shift_2d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid = np.arange(data[\"contact_force\"].shape[0]) * 1e-4\n",
    "fig, axs = plt.subplots(3, 1, figsize=(9, 6), tight_layout=True, sharex=True)\n",
    "for i, leg_pair in enumerate([\"Front\", \"Middle\", \"Hind\"]):\n",
    "    ax = axs[i]\n",
    "    ax.plot(t_grid, data[\"contact_force\"][:, i], lw=1, label=\"Left\")\n",
    "    ax.plot(t_grid, data[\"contact_force\"][:, i + 3], lw=1, label=\"Right\")\n",
    "    ax.set_xlim(2.5, 3)\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(f\"{leg_pair} leg contact force\")\n",
    "    ax.set_ylabel(\"Force (mN)\")\n",
    "    if i == 2:\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "    if i == 0:\n",
    "        ax.legend(ncols=2, loc=\"upper right\")\n",
    "fig.savefig(output_dir / \"ee_contact_force.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contact force time series, we can observe that:\n",
    "\n",
    "1. There are roughly 6 groups of non-zero blocks per time series. These are the 6 stance phases per line over the period of 0.5 seconds (the CPG frequency is 12 Hz).\n",
    "2. The two sides are not necessarily symmetrical. This is because the fly might turn during walking.\n",
    "3. The hind leg has a lower signal-to-noise ratio than the front and middle legs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will inspect the fly's orientation and position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), tight_layout=True)\n",
    "\n",
    "unwrapped_heading = np.unwrap(data[\"fly_orientation_angle\"])\n",
    "axs[0].plot(t_grid, np.rad2deg(unwrapped_heading), lw=1, color=\"k\")\n",
    "axs[0].set_xlabel(\"Time (s)\")\n",
    "axs[0].set_ylabel(r\"Heading ($^\\circ$)\")\n",
    "axs[0].set_title(\"Fly heading\")\n",
    "\n",
    "axs[1].plot(data[\"fly_pos\"][:, 0], data[\"fly_pos\"][:, 1], lw=1, color=\"k\")\n",
    "axs[1].plot([0], [0], \"ko\", label=\"Origin\")\n",
    "axs[1].set_aspect(\"equal\")\n",
    "axs[1].set_xlabel(\"x position (mm)\")\n",
    "axs[1].set_ylabel(\"y position (mm)\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "axs[1].set_title(\"Fly trajectory\")\n",
    "\n",
    "fig.savefig(output_dir / \"heading_and_trajectory.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the algorithm that we have proposed. To train the models, we need to collect the following _input_ variables to the model:\n",
    "\n",
    "- Difference in the left-right _sum_ of cumulated stride lengths, `stride_total_diff_lrsum`\n",
    "- Difference in the left-right _difference_ of cumulated stride lengths, `stride_total_diff_lrdiff`\n",
    "\n",
    "... and the following _target_ variables (i.e., what the models are supposed to predict):\n",
    "\n",
    "- Difference in the fly's heading, `heading_diff`\n",
    "- Difference in the fly's total forward displacement, `forward_disp_total_diff`\n",
    "\n",
    "There are two things to note here:\n",
    "\n",
    "1. We have not implemented the calculation of stride lengths yet; `stride_diff_unmasked` is only the shift of the leg tip position from one time step to the next.\n",
    "2. As discussed in the Algorithm section, the differences above are calculated over a predefined time scale $\\tau$.\n",
    "\n",
    "To calculate the cumulated stride lengths given `stride_diff_unmasked`, we need to mask it with a boolean time series indicating whether the leg is \"pushing\" (as opposed to swinging) before taking the cumulative sum. More precisely,\n",
    "\n",
    "$$ \n",
    "\\begin{gather*}\n",
    "    \\text{stride\\_total}[0] = 0 \\\\\n",
    "    \\text{stride\\_total}[i] = \\text{stride\\_total}[i - 1] +\n",
    "        \\big( \\text{mask}[i] \\cdot \\text{ stride\\_diff\\_unmasked}[i] \\big)\n",
    "    \\quad \\text{for } i > 0\n",
    "\\end{gather*}\n",
    "$$\n",
    "\n",
    "where $\\text{mask}[i]$ is a boolean indicating whether the leg is in the power stroke (push). In our example, we will use the ground contact force to determine if the leg is in contact with the floor. If it is, then the leg is executing a power stroke. We will use a threshold of 0.5 mN, 1 mN, and 3mN for the front, middle, and hind legs respectively.\n",
    "\n",
    "Once we have the cumulative stride lengths for each leg, we can calculate how it changes over the predefined time scale $\\tau$:\n",
    "\n",
    "$$\n",
    "\\text{stride\\_total\\_diff}[i] =\n",
    "    \\text{stride\\_total}[i] - \\text{stride\\_total}[i - \\text{window\\_len}]\n",
    "$$\n",
    "\n",
    "where $\\text{window\\_len} = \\tau / \\Delta t$ is the number of simulation steps over the time scale $\\tau$.\n",
    "\n",
    "With this, we can finally calculate the changes in the left-right sum and left-right difference of cumulative stride lengths for each leg pair over time:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{stride\\_total\\_diff\\_lrsum}[i] &= \n",
    "        \\text{stride\\_total\\_diff}_\\text{left}[i] +\n",
    "        \\text{stride\\_total\\_diff}_\\text{right}[i] \\\\\n",
    "    \\text{stride\\_total\\_diff\\_lrdiff}[i] &= \n",
    "        \\text{stride\\_total\\_diff}_\\text{left}[i] -\n",
    "        \\text{stride\\_total\\_diff}_\\text{right}[i] \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having extracted the _input_ variables, we will next extract the target _output_ variables: the changes in the fly's heading and forward displacement over the same time scale.\n",
    "\n",
    "Calculating the change in the fly's heading is straightforward: for each simulation step $i$,\n",
    "$$\n",
    "\\text{heading\\_diff}[i] = \\text{heading}[i] - \\text{heading}[i - \\text{window\\_len}]\n",
    "\\quad \\text{wrapped to $[-\\pi, \\pi)$}\n",
    "$$\n",
    "where $\\text{heading}$ is the heading angle.\n",
    "\n",
    "To calculate the change in the fly's forward displacement, we first have to accumulate the forward displacement from one step to the next over the whole simulation. We will call this variable $\\text{forward\\_disp}$. This sounds simply like the total travel distance, but the critical difference is that at the scale of single simulation steps, we discard lateral movements. Then, similar to the change in heading, we can simply calculate the cumulative forward displacement over the time period of $\\tau$:\n",
    "\n",
    "$$\n",
    "\\begin{gather*}\n",
    "    \\text{forward\\_disp}[0] = 0, \\\\\n",
    "    \\text{forward\\_disp}[i] =\n",
    "        \\text{forward\\_disp}[i - 1] + \\text{d\\_forward\\_disp}[i]\n",
    "    \\quad\\text{for } i > 0\n",
    "\\end{gather*}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\text{d\\_forward\\_disp}[i] = (\\overrightarrow{\\text{position}}[i] -\n",
    "        \\overrightarrow{\\text{position}}[i - 1]) \\cdot\n",
    "        \\begin{bmatrix}\n",
    "            \\cos(\\text{heading}[i])\\\\\n",
    "            \\sin(\\text{heading}[i])\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\overrightarrow{\\text{position}}[i]$ is the fly's vector position (x-y) at simulation step $i$.\n",
    "\n",
    "With this, the change in total forward displacement is:\n",
    "$$\n",
    "\\text{forward\\_disp\\_diff}[i] =\n",
    "    \\text{forward\\_disp}[i] -\n",
    "    \\text{forward\\_disp}[i - \\text{window\\_len}]\n",
    "$$\n",
    "\n",
    "Let's implement a function that extracts these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables(\n",
    "    trial_data: dict[str, np.ndarray],\n",
    "    time_scale: float,\n",
    "    contact_force_thr: tuple[float, float, float],\n",
    "    dt: float = 1e-4,\n",
    ") -> dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract variables used for path integration from trial data.\n",
    "    The difference between ``load_trial_data`` and ``extract_variables`` is\n",
    "    that the former loads the raw data from the trial (i.e., physics\n",
    "    simulation). The latter extracts variables from these raw data subject\n",
    "    to additional parameters such as time scale. For each trial, we only\n",
    "    call ``load_trial_data`` once, but we may call ``extract_variables``\n",
    "    multiple times with different parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_data : dict[str, np.ndarray]\n",
    "        Dictionary containing trial data.\n",
    "    time_scale : float\n",
    "        Time scale for path integration.\n",
    "    contact_force_thr : tuple[float, float, float]\n",
    "        Thresholds for contact forces. These are used to determine whether\n",
    "        a leg is in contact with the ground.\n",
    "    dt : float, optional\n",
    "        Time step of the physics simulation in the trial, by default 1e-4.\n",
    "    \"\"\"\n",
    "    window_len = int(time_scale / dt)\n",
    "    # contact force thresholds: (3,) -> (6,), for both sides\n",
    "    contact_force_thr = np.array([*contact_force_thr, *contact_force_thr])\n",
    "\n",
    "    # Mechanosensory signal ==========\n",
    "    # Calculate total stride (Σstride) for each side\n",
    "    stride_left = trial_data[\"end_effector_pos_diff\"][:, :3, 0]  # (L, 3)\n",
    "    stride_right = trial_data[\"end_effector_pos_diff\"][:, 3:, 0]  # (L, 3)\n",
    "    contact_mask = trial_data[\"contact_force\"] > contact_force_thr[None, :]  # (L, 6)\n",
    "    stride_left = stride_left * contact_mask[:, :3]\n",
    "    stride_right = stride_right * contact_mask[:, 3:]\n",
    "    stride_total_left = np.cumsum(stride_left, axis=0)\n",
    "    stride_total_right = np.cumsum(stride_right, axis=0)\n",
    "\n",
    "    # Calculate difference in Σstride over proprioceptive time window (ΔΣstride)\n",
    "    stride_total_diff_left = (\n",
    "        stride_total_left[window_len:] - stride_total_left[:-window_len]\n",
    "    )\n",
    "    stride_total_diff_right = (\n",
    "        stride_total_right[window_len:] - stride_total_right[:-window_len]\n",
    "    )\n",
    "\n",
    "    # Calculate sum and difference in ΔΣstride over two sides\n",
    "    stride_total_diff_lrsum = stride_total_diff_left + stride_total_diff_right\n",
    "    stride_total_diff_lrdiff = stride_total_diff_left - stride_total_diff_right\n",
    "\n",
    "    # Change in locomotion state (heading & displacement) ==========\n",
    "    # Calculate change in fly orientation over proprioceptive time window (Δheading)\n",
    "    fly_orientation_xy = trial_data[\"fly_orientation_xy\"]\n",
    "    fly_orientation_angle = trial_data[\"fly_orientation_angle\"]\n",
    "    heading_diff = (\n",
    "        fly_orientation_angle[window_len:] - fly_orientation_angle[:-window_len]\n",
    "    )\n",
    "    heading_diff = (heading_diff + np.pi) % (2 * np.pi) - np.pi  # wrap to [-π, π]\n",
    "\n",
    "    # Same for displacement projected in the direction of fly's heading\n",
    "    # Use projection formula: proj_v(u) = (u · v) / (v · v) * v where v is the fly's\n",
    "    # heading vector and u is the change in position\n",
    "    fly_disp_xy = np.diff(trial_data[\"fly_pos\"], axis=0, prepend=0)\n",
    "    fly_orientation_xy_norm = np.linalg.norm(fly_orientation_xy, axis=1)\n",
    "    fly_orientation_xy_unit = fly_orientation_xy / fly_orientation_xy_norm[:, None]\n",
    "    udotv = np.sum(fly_disp_xy * fly_orientation_xy_unit, axis=1)\n",
    "    vdotv = np.sum(fly_orientation_xy_unit * fly_orientation_xy_unit, axis=1)\n",
    "    forward_disp_mag = udotv / vdotv\n",
    "    forward_disp_total = np.cumsum(forward_disp_mag)\n",
    "    forward_disp_total_diff = (\n",
    "        forward_disp_total[window_len:] - forward_disp_total[:-window_len]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"stride_total_diff_lrsum\": stride_total_diff_lrsum.astype(np.float32),\n",
    "        \"stride_total_diff_lrdiff\": stride_total_diff_lrdiff.astype(np.float32),\n",
    "        \"heading_diff\": heading_diff.astype(np.float32),\n",
    "        \"forward_disp_total_diff\": forward_disp_total_diff.astype(np.float32),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to extract the input and target variables at a time scale of 0.32 s using a contact force threshold of 0.5 mN, 1 mN, and 3 mN for the front, middle, and hind legs respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale = 0.32\n",
    "contact_force_thr = (0.5, 1, 3)\n",
    "extracted_variables = [\n",
    "    extract_variables(data, time_scale, contact_force_thr) for data in trial_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to predict the change in forward displacement from the changes in left-right sums, and the change in heading from the left-right differences. Let's plot these variable in one trial to decide if these are qualitatively good predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_vars = extracted_variables[0]\n",
    "t_grid_trim = t_grid[-ext_vars[\"stride_total_diff_lrsum\"].shape[0] :]\n",
    "fig, axs = plt.subplots(2, 1, figsize=(9, 6), tight_layout=True, sharex=True)\n",
    "\n",
    "axs[0].axhline(0, color=\"k\", linestyle=\"--\", lw=1)\n",
    "for i, leg in enumerate([\"Front\", \"Middle\", \"Hind\"]):\n",
    "    axs[0].plot(\n",
    "        t_grid_trim,\n",
    "        -ext_vars[\"stride_total_diff_lrsum\"][:, i],\n",
    "        lw=1,\n",
    "        label=f\"ΔL-R sum ({leg.lower()})\",\n",
    "    )\n",
    "axs[0].plot(\n",
    "    t_grid_trim,\n",
    "    ext_vars[\"forward_disp_total_diff\"],\n",
    "    lw=2,\n",
    "    color=\"k\",\n",
    "    label=\"Δforward displacement\",\n",
    ")\n",
    "axs[0].legend(loc=\"upper center\", ncol=4)\n",
    "axs[0].set_ylabel(\"Length (mm)\")\n",
    "axs[0].set_ylim(-2, 10)\n",
    "axs[0].set_title(\"Δforward displacement predictors and target\")\n",
    "\n",
    "axs[1].axhline(0, color=\"k\", linestyle=\"--\", lw=1)\n",
    "for i, leg in enumerate([\"Front\", \"Middle\", \"Hind\"]):\n",
    "    axs[1].plot(\n",
    "        t_grid_trim,\n",
    "        -ext_vars[\"stride_total_diff_lrdiff\"][:, i],\n",
    "        lw=1,\n",
    "        label=f\"ΔL-R difference ({leg.lower()})\",\n",
    "    )\n",
    "axs[1].plot(\n",
    "    t_grid_trim,\n",
    "    -ext_vars[\"heading_diff\"],\n",
    "    lw=2,\n",
    "    color=\"k\",\n",
    "    label=\"Δheading\",\n",
    ")\n",
    "axs[1].legend(loc=\"upper center\", ncol=4)\n",
    "axs[1].set_ylabel(\"Length (mm)\")\n",
    "axs[1].set_xlabel(\"Time (s)\")\n",
    "axs[1].set_ylim(-6, 6)\n",
    "axs[1].set_title(\"Δheading predictors and target\")\n",
    "\n",
    "fig.savefig(output_dir / \"pathint_predictors_and_target.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the inputs (blue, orange, and green lines) indeed seem to be good predictors of the target (black lines). Next, we will train the prediction models based on our proposed algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models to predict changes in locomotor state\n",
    "\n",
    "Once the input and target variables have been extracted, training the models themselves is relatively easy. As discussed, we will train two linear models to predict the changes in forward displacement and heading using changes in the left-right sums and differences in cumulative stride lengths:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{heading\\_diff\\_pred}[i] &=\n",
    "        \\sum_{pos\\in\\{\\text{front}, \\text{middle}, \\text{hind}\\}}\n",
    "            \\big(\n",
    "                k_{pos}^{({\\rm h})} \\cdot \\text{stride\\_total\\_diff\\_lrsum}_{pos}[i]\n",
    "            \\big) + b^{({\\rm h})} \\\\\n",
    "    \\text{forward\\_disp\\_diff\\_pred}[i] &=\n",
    "        \\sum_{pos\\in\\{\\text{front}, \\text{middle}, \\text{hind}\\}}\n",
    "            \\big(\n",
    "                k_{pos}^{({\\rm fd})} \\cdot \\text{stride\\_total\\_diff\\_lrdiff}_{pos}[i]\n",
    "            \\big) + b^{({\\rm fd})} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\text{heading\\_diff\\_pred}$ and $\\text{forward\\_disp\\_diff\\_pred}$ are the model's predictions of $\\text{heading\\_diff}$ and $\\text{forward\\_disp\\_diff}$; $k_{pos}^{({\\rm h})}$, $b^{({\\rm h})}$, $k_{pos}^{({\\rm fd})}$, and $b^{({\\rm fd})}$ are the parameters to be fitted. While we are using all three pairs of legs in this example, a different set of legs can be used instead.\n",
    "\n",
    "Recall that we have 5 trials per gait type. We will concatenate the first 4 trials to form the training set, and then use the last trial for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_total_diff_lrsum_train = np.concatenate(\n",
    "    [ext_vars[\"stride_total_diff_lrsum\"] for ext_vars in extracted_variables[:4]]\n",
    ")\n",
    "stride_total_diff_lrdiff_train = np.concatenate(\n",
    "    [ext_vars[\"stride_total_diff_lrdiff\"] for ext_vars in extracted_variables[:4]]\n",
    ")\n",
    "heading_diff_train = np.concatenate(\n",
    "    [ext_vars[\"heading_diff\"] for ext_vars in extracted_variables[:4]]\n",
    ")\n",
    "forward_disp_total_diff_train = np.concatenate(\n",
    "    [ext_vars[\"forward_disp_total_diff\"] for ext_vars in extracted_variables[:4]]\n",
    ")\n",
    "stride_total_diff_lrsum_test = extracted_variables[4][\"stride_total_diff_lrsum\"]\n",
    "stride_total_diff_lrdiff_test = extracted_variables[4][\"stride_total_diff_lrdiff\"]\n",
    "heading_diff_test = extracted_variables[4][\"heading_diff\"]\n",
    "forward_disp_total_diff_test = extracted_variables[4][\"forward_disp_total_diff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will train the linear models using the `LinearRegression` class from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def fit_1d_linear_model(x: np.ndarray, y: np.ndarray) -> tuple[LinearRegression, float]:\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    r2 = model.score(x, y)\n",
    "    return model, r2\n",
    "\n",
    "\n",
    "heading_model, heading_model_r2 = fit_1d_linear_model(\n",
    "    stride_total_diff_lrdiff_train, heading_diff_train\n",
    ")\n",
    "fwd_disp_model, fwd_disp_model_r2 = fit_1d_linear_model(\n",
    "    stride_total_diff_lrsum_train, forward_disp_total_diff_train\n",
    ")\n",
    "print(\"Δheading model:\")\n",
    "print(f\"  coefficients (front, middle, hind legs): {heading_model.coef_}\")\n",
    "print(f\"  intercept: {heading_model.intercept_}\")\n",
    "print(f\"  r2 score (training set): {heading_model_r2}\")\n",
    "print(\"Δforward displacement model:\")\n",
    "print(f\"  coefficients (front, middle, hind legs): {fwd_disp_model.coef_}\")\n",
    "print(f\"  intercept: {fwd_disp_model.intercept_}\")\n",
    "print(f\"  r2 score (training set): {fwd_disp_model_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating changes in locomotor state to estimate position\n",
    "\n",
    "Now that we have built models that can estimate the changes in heading and forward displacement, we will integrate these changes to estimate the fly's location in space. To do this, we essentially reverse the process of extracting the change signals: whereas previously we have taken the per-step changes in cumulative stride lengths as an estimation of instantaneous changes, we will now sum these changes as an approximation of continuous integration.\n",
    "\n",
    "More formally, from the model-predicted change in heading, $\\text{heading\\_diff\\_pred}$, the estimated heading can be given by\n",
    "$$\n",
    "\\text{heading\\_pred}[i] =\n",
    "    \\sum_{i'=0}^i \\frac{\\text{heading\\_diff\\_pred}[i']}{\\text{window\\_len}}\n",
    "$$\n",
    "where, once again, $\\text{window\\_len} = \\tau / \\Delta t$ is the number of simulation steps over the time scale $\\tau$.\n",
    "\n",
    "To obtain the estimated position vector, $\\overrightarrow{\\text{position\\_pred}}$, we have to take into account the fact that the change in _forward_ displacement must be integrated in the direction of the fly's instantaneous heading:\n",
    "$$\n",
    "\\overrightarrow{\\text{position\\_pred}}[i] =\n",
    "    \\sum_{i'=0}^i \\frac{\\text{fwd\\_disp\\_diff\\_pred}[i']}{\\text{window\\_len}}\n",
    "    \\begin{bmatrix}\n",
    "        \\cos(\\text{heading\\_pred}[i'])\\\\\n",
    "        \\sin(\\text{heading\\_pred}[i'])\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We will now implement this integration logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def path_integrate(\n",
    "    trial_data: dict[str, np.ndarray],\n",
    "    heading_model: Callable,\n",
    "    displacement_model: Callable,\n",
    "    time_scale: float,\n",
    "    contact_force_thr: tuple[float, float, float],\n",
    "    dt: float = 1e-4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform path integration on trial data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_data : dict[str, np.ndarray]\n",
    "        Dictionary containing trial data.\n",
    "    heading_model : Callable\n",
    "        Model for predicting change in heading.\n",
    "    displacement_model : Callable\n",
    "        Model for predicting change in displacement.\n",
    "    time_scale : float\n",
    "        Time scale for path integration.\n",
    "    contact_force_thr : tuple[float, float, float]\n",
    "        Thresholds for contact forces. These are used to determine whether\n",
    "        a leg is in contact with the ground.\n",
    "    dt : float\n",
    "        Time step of the physics simulation in the trial.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, np.ndarray]\n",
    "        Dictionary containing the following keys:\n",
    "        * \"heading_pred\": Predicted heading.\n",
    "        * \"heading_actual\": Actual heading.\n",
    "        * \"pos_pred\": Predicted position.\n",
    "        * \"pos_actual\": Actual position.\n",
    "        * \"heading_diff_pred\": Predicted change in heading.\n",
    "        * \"heading_diff_actual\": Actual change in heading.\n",
    "        * \"displacement_diff_pred\": Predicted change in displacement.\n",
    "        * \"displacement_diff_actual\": Actual change in displacement.\n",
    "    \"\"\"\n",
    "    window_len = int(time_scale / dt)\n",
    "    variables = extract_variables(\n",
    "        trial_data, time_scale=time_scale, contact_force_thr=contact_force_thr, dt=dt\n",
    "    )\n",
    "\n",
    "    # Integrate heading\n",
    "    heading_diff_pred = heading_model(variables[\"stride_total_diff_lrdiff\"])\n",
    "    heading_pred = np.cumsum(heading_diff_pred / window_len)\n",
    "    # Path int. not performed when not enough data is available. Start from the real\n",
    "    # heading at the moment when path int. actually starts.\n",
    "    hx_start, hy_start = trial_data[\"fly_orientation_xy\"][window_len, :]\n",
    "    real_heading_start = np.arctan2(hy_start, hx_start)\n",
    "    heading_pred += real_heading_start\n",
    "\n",
    "    # Integrate displacement\n",
    "    displacement_diff_pred = displacement_model(variables[\"stride_total_diff_lrsum\"])\n",
    "    displacement_diff_x_pred = np.cos(heading_pred) * displacement_diff_pred\n",
    "    displacement_diff_y_pred = np.sin(heading_pred) * displacement_diff_pred\n",
    "    pos_x_pred = np.cumsum(displacement_diff_x_pred / window_len)\n",
    "    pos_y_pred = np.cumsum(displacement_diff_y_pred / window_len)\n",
    "    pos_x_pred += trial_data[\"fly_pos\"][window_len, 0]\n",
    "    pos_y_pred += trial_data[\"fly_pos\"][window_len, 1]\n",
    "    pos_pred = np.concatenate([pos_x_pred[:, None], pos_y_pred[:, None]], axis=1)\n",
    "\n",
    "    # Pad with NaN where prediction not available\n",
    "    padding = np.full(window_len, np.nan)\n",
    "    heading_pred = np.concatenate([padding, heading_pred])\n",
    "    pos_pred = np.concatenate([np.full((window_len, 2), np.nan), pos_pred], axis=0)\n",
    "    heading_diff_pred = np.concatenate([padding, heading_diff_pred])\n",
    "    heading_diff_actual = np.concatenate([padding, variables[\"heading_diff\"]])\n",
    "    displacement_diff_pred = np.concatenate([padding, displacement_diff_pred])\n",
    "    displacement_diff_actual = np.concatenate(\n",
    "        [padding, variables[\"forward_disp_total_diff\"]]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"heading_pred\": heading_pred,\n",
    "        \"heading_actual\": trial_data[\"fly_orientation_angle\"],\n",
    "        \"pos_pred\": pos_pred,\n",
    "        \"pos_actual\": trial_data[\"fly_pos\"],\n",
    "        \"heading_diff_pred\": heading_diff_pred,\n",
    "        \"heading_diff_actual\": heading_diff_actual,\n",
    "        \"displacement_diff_pred\": displacement_diff_pred,\n",
    "        \"displacement_diff_actual\": displacement_diff_actual,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this function on the last trial, which has been reserved for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_integration_res = path_integrate(\n",
    "    trial_data[4],\n",
    "    heading_model.predict,  # this is LinearRegression's method for making prediction\n",
    "    fwd_disp_model.predict,  # \"\n",
    "    time_scale,\n",
    "    contact_force_thr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and inspect the time series of predicted vs. actual changes in heading and forward displacement on this test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(6, 4), tight_layout=True, sharex=True)\n",
    "\n",
    "axs[0].plot(\n",
    "    t_grid,\n",
    "    np.rad2deg(path_integration_res[\"heading_diff_actual\"]),\n",
    "    lw=1,\n",
    "    color=\"black\",\n",
    "    label=\"Actual\",\n",
    ")\n",
    "axs[0].plot(\n",
    "    t_grid,\n",
    "    np.rad2deg(path_integration_res[\"heading_diff_pred\"]),\n",
    "    lw=1,\n",
    "    color=\"tab:red\",\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "axs[0].set_ylabel(r\"Δheading ($^\\circ$)\")\n",
    "axs[0].set_ylim(-90, 90)\n",
    "axs[0].legend(loc=\"lower left\", ncols=2)\n",
    "\n",
    "axs[1].plot(\n",
    "    t_grid,\n",
    "    np.rad2deg(path_integration_res[\"displacement_diff_actual\"]),\n",
    "    lw=1,\n",
    "    color=\"black\",\n",
    "    label=\"Actual\",\n",
    ")\n",
    "axs[1].plot(\n",
    "    t_grid,\n",
    "    np.rad2deg(path_integration_res[\"displacement_diff_pred\"]),\n",
    "    lw=1,\n",
    "    color=\"tab:red\",\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "axs[1].set_ylabel(\"Δfwd. disp. (mm)\")\n",
    "axs[1].set_ylim(50, 300)\n",
    "axs[1].legend(loc=\"lower left\", ncols=2)\n",
    "axs[1].set_xlabel(\"Time (s)\")\n",
    "fig.savefig(output_dir / \"path_integration_diff.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can plot the integrated estimation of heading and total forward displacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(6, 4), tight_layout=True, sharex=True)\n",
    "\n",
    "axs[0].plot(\n",
    "    t_grid,\n",
    "    np.rad2deg(np.unwrap(path_integration_res[\"heading_actual\"])),\n",
    "    lw=1,\n",
    "    color=\"black\",\n",
    "    label=\"Actual\",\n",
    ")\n",
    "axs[0].plot(\n",
    "    t_grid,\n",
    "    np.rad2deg(path_integration_res[\"heading_pred\"]),\n",
    "    lw=1,\n",
    "    color=\"tab:red\",\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "axs[0].set_ylabel(r\"Heading ($^\\circ$)\")\n",
    "axs[0].legend(loc=\"lower left\", ncols=2)\n",
    "\n",
    "fwd_disp_total_actual = np.cumsum(\n",
    "    np.nan_to_num(path_integration_res[\"displacement_diff_actual\"])\n",
    ") / (time_scale / 1e-4)\n",
    "fwd_disp_total_pred = np.cumsum(\n",
    "    np.nan_to_num(path_integration_res[\"displacement_diff_pred\"])\n",
    ") / (time_scale / 1e-4)\n",
    "axs[1].plot(\n",
    "    t_grid,\n",
    "    fwd_disp_total_actual,\n",
    "    lw=1,\n",
    "    color=\"black\",\n",
    "    label=\"Actual\",\n",
    ")\n",
    "axs[1].plot(\n",
    "    t_grid,\n",
    "    fwd_disp_total_pred,\n",
    "    lw=1,\n",
    "    color=\"tab:red\",\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "axs[1].set_ylabel(\"Cumulative fwd. disp. (mm)\")\n",
    "axs[1].legend(loc=\"lower right\", ncols=2)\n",
    "axs[1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "fig.savefig(output_dir / \"path_integration_cumulative.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the estimated and true trajectories of the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4), tight_layout=True)\n",
    "\n",
    "ax.plot(\n",
    "    path_integration_res[\"pos_actual\"][:, 0],\n",
    "    path_integration_res[\"pos_actual\"][:, 1],\n",
    "    lw=1,\n",
    "    color=\"black\",\n",
    "    label=\"Actual\",\n",
    ")\n",
    "ax.plot(\n",
    "    path_integration_res[\"pos_pred\"][:, 0],\n",
    "    path_integration_res[\"pos_pred\"][:, 1],\n",
    "    lw=1,\n",
    "    color=\"tab:red\",\n",
    "    label=\"Predicted\",\n",
    ")\n",
    "ax.plot([0], [0], \"ko\", label=\"Origin\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"x position (mm)\")\n",
    "ax.set_ylabel(\"y position (mm)\")\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(-50, 50)\n",
    "ax.legend(loc=\"lower left\")\n",
    "fig.savefig(output_dir / \"path_integration_trajectory.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that, although the model gives excellent predictions in heading and forward displacement, small errors in heading can lead to larger errors in the final position estimation. This is simply due to the fact that walking straight in a slightly wrong direction amplifies the error in the estimated position. Therefore, while path integration based solely on idiothetic cues is possible, calibration of the integrator based on sensory inputs appears to be critical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
