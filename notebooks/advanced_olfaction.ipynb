{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced olfaction: Navigating a complex odor plume\n",
    "\n",
    "**Author:** Victor Alfred Stimpfling\n",
    "\n",
    "**Note:** The code presented in this notebook has been simplified and restructured for display in a notebook format. A more complete and better structured implementation can be found in the [examples folder of the FlyGym repository on GitHub](https://github.com/NeLy-EPFL/flygym/tree/main/flygym/examples/).\n",
    "\n",
    "**Summary**: In this tutorial, we simulate a complex odor plume, replay the plume in MuJoCo, and build a simple controller to navigate it.\n",
    "\n",
    "\n",
    "We have shown, in [a previous tutorial](https://neuromechfly.org/tutorials/olfaction.html), that our model is able to navigate a static odor gradient. In nature, static odor gradients are rather rare. On the contrary, dynamic plumes (c.f. illustration from [Demir et al, 2020](https://doi.org/10.7554/eLife.57524) below) with short intermittent bursts are more common. In such environments, odor gradients carry only limited information regarding the position of odor source. Consequently, navigating an odor plume requires multimodal integration of both wind and odor. In this notebook, we will demonstrate how one can create an odor plume using [PhiFlow](https://tum-pbs.github.io/PhiFlow/), a partial differential equations solver designed for machine learning that solves the Navier-Stokes equations to model the dynamics of a complex plume. We will also show how this plume dataset can be plugged into NeuroMechFly. Finally, we will design a very simple controller that can successfully navigate a complex plume based on the algorithm proposed in [Demir et al, 2020](https://doi.org/10.7554/eLife.57524).\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/NeLy-EPFL/_media/blob/main/flygym/plume_tracking/demir_et_al_real_odour_plume.jpg?raw=true\" alt=\"complex plume\" width=\"500\"/>\n",
    "<br>\n",
    "<em>Image from <a href=\"https://doi.org/10.7554/eLife.57524\">Demir et al, 2020</a>.</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a complex odor plume\n",
    "\n",
    "To demonstrate the flexibility of our framework, we will simulate an arbitrary odor plume resembling those in [Demir et al. 2020](https://doi.org/10.7554/eLife.57524). Our plume is modelled as a distinct substance embedded in an incompressible fluid. This is analogous to, for example, a food odor embedded in air. We simulate the plume by solving the Navier—Stokes equations in 2D. Our simulation is initialized with a constant velocity field, producing a right-bound \"wind\". In addition to the wind, we inject random perturbations as external forces exerted on the smoke. The force vector moves in Brownian motion, akin to random wind bursts driving turbulent flow.\n",
    "\n",
    "Although we are simulating the plume in this tutorial, one can also replay an experimentally recorded plume dataset.\n",
    "\n",
    "To generate your own plume, make sure you have installed PhiFlow. This should have been done already if you installed the \"examples\" optional dependency of flygym (`pip install \"flygym[examples]\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decide on a few hyperparameters defining our plume:\n",
    "\n",
    "- The size of the arena\n",
    "- A scaling factor (i.e., spatial resolution) for the velocity and smoke grids\n",
    "- The position and size of the inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is partially based on the following script by  Felix Köhler:\n",
    "# https://github.com/Ceyron/machine-learning-and-simulation/blob/main/english/phiflow/smoke_plume.py\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from phi.torch import flow\n",
    "from typing import Tuple\n",
    "from tqdm import trange\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(0)\n",
    "# change the simulation time to have a shorter simulation\n",
    "simulation_time = 20.0\n",
    "dt = 0.05\n",
    "arena_size = (80, 60)\n",
    "inflow_pos = (4, 30)\n",
    "inflow_radius = 1\n",
    "inflow_scaler = 0.2\n",
    "velocity_grid_size = 0.5\n",
    "smoke_grid_size = 0.25\n",
    "simulation_steps = int(simulation_time / dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the dynamics of the plume in more detail. In particular, we load a helper function that outputs the Brownian contribution to the total wind at every time step.\n",
    "\n",
    "```Python\n",
    "def converging_brownian_step(\n",
    "    value_curr: np.ndarray,\n",
    "    center: np.ndarray,\n",
    "    gaussian_scale: float = 1.0,\n",
    "    convergence: float = 0.5,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Step to simulate Brownian noise with convergence towards a center.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value_curr : np.ndarray\n",
    "        Current value of variables (i.e., noise) in Brownian motion.\n",
    "    center : np.ndarray\n",
    "        Center towards which the Brownian motion converges.\n",
    "    gaussian_scale : float, optional\n",
    "        Standard deviation of Gaussian noise to be added to the current\n",
    "        value, by default 1.0\n",
    "    convergence : float, optional\n",
    "        Factor of convergence towards the center, by default 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Next value of variables (i.e., noise) in Brownian motion.\n",
    "    \"\"\"\n",
    "    gaussian_center = (center - value_curr) * convergence\n",
    "    value_diff = np.random.normal(\n",
    "        loc=gaussian_center, scale=gaussian_scale, size=value_curr.shape\n",
    "    )\n",
    "    value_next = value_curr + value_diff\n",
    "    return value_next\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.examples.olfaction.simulate_plume_dataset import converging_brownian_step\n",
    "\n",
    "# Simulate Brownian noise and store the wind for every time step\n",
    "curr_wind = np.zeros((2,))\n",
    "wind_hist = [curr_wind.copy()]\n",
    "for i in range(simulation_steps):\n",
    "    curr_wind = converging_brownian_step(curr_wind, (0, 0), (1.2, 1.2), 1.0)\n",
    "    wind_hist.append(curr_wind.copy())\n",
    "\n",
    "# Define simulation grids\n",
    "# constant velocity vector in every points\n",
    "velocity = flow.StaggeredGrid(\n",
    "    values=(10.0, 0.0),  # constant velocity field to the right\n",
    "    extrapolation=flow.extrapolation.BOUNDARY,\n",
    "    x=int(arena_size[0] / velocity_grid_size),\n",
    "    y=int(arena_size[1] / velocity_grid_size),\n",
    "    bounds=flow.Box(x=arena_size[0], y=arena_size[1]),\n",
    ")\n",
    "\n",
    "# choose extrapolation mode from\n",
    "# ('undefined', 'zeros', 'boundary', 'periodic', 'symmetric', 'reflect')\n",
    "# Zero smoke field at the beginning of the simulation\n",
    "smoke = flow.CenteredGrid(\n",
    "    values=0.0,\n",
    "    extrapolation=flow.extrapolation.BOUNDARY,\n",
    "    x=int(arena_size[0] / smoke_grid_size),\n",
    "    y=int(arena_size[1] / smoke_grid_size),\n",
    "    bounds=flow.Box(x=arena_size[0], y=arena_size[1]),\n",
    ")\n",
    "\n",
    "# Define inflow\n",
    "inflow = inflow_scaler * flow.field.resample(\n",
    "    flow.Sphere(x=inflow_pos[0], y=inflow_pos[1], radius=inflow_radius),\n",
    "    to=smoke,\n",
    "    soft=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the velocity field, the smoke density, and the inflow at the beginning of the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from phi import vis\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"outputs/plume_tracking\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig = vis.plot(velocity, title=\"Wind velocity\", size=(5, 4))\n",
    "plt.gcf().savefig(output_dir / \"wind_velocity_t0.png\")\n",
    "\n",
    "fig = vis.plot(smoke, title=\"Smoke density\", size=(5, 4), show_color_bar=False)\n",
    "plt.gcf().savefig(output_dir / \"smoke_density_t0.png\")\n",
    "\n",
    "fig = vis.plot(inflow, title=\"Inflow\", size=(5, 4), show_color_bar=False)\n",
    "plt.gcf().savefig(output_dir / \"inflow_t0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to simulate the plume. For that we use the following step function:\n",
    "\n",
    "```Python\n",
    "def step(\n",
    "    velocity_prev: flow.Grid,\n",
    "    smoke_prev: flow.Grid,\n",
    "    noise: np.ndarray,\n",
    "    noise_magnitude: Tuple[float, float] = (0.1, 2),\n",
    "    dt: float = 1.0,\n",
    "    inflow: flow.Grid = None,\n",
    "    ) -> Tuple[flow.Grid, flow.Grid]:\n",
    "    \"\"\"Simulate fluid dynamics by one time step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    velocity_prev : flow.Grid\n",
    "        Velocity field at previous time step.\n",
    "    smoke_prev : flow.Grid\n",
    "        Smoke density at previous time step.\n",
    "    noise : np.ndarray\n",
    "        Brownian noise to be applied as external force.\n",
    "    noise_magnitude : Tuple[float, float], optional\n",
    "        Magnitude of noise to be applied as external force in x and y\n",
    "        directions, by default (0.1, 2)\n",
    "    dt : float, optional\n",
    "        Simulation time step, by default 1.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[flow.Grid, flow.Grid]\n",
    "        Velocity field and smoke density at next time step.\n",
    "    \"\"\"\n",
    "    smoke_next = flow.advect.mac_cormack(smoke_prev, velocity_prev, dt=dt) + inflow\n",
    "    external_force = smoke_next * noise * noise_magnitude @ velocity_prev\n",
    "    velocity_tentative = (\n",
    "        flow.advect.semi_lagrangian(velocity_prev, velocity_prev, dt=dt)\n",
    "        + external_force\n",
    "    )\n",
    "    velocity_next, pressure = flow.fluid.make_incompressible(velocity_tentative)\n",
    "    return velocity_next, smoke_next\n",
    "```\n",
    "\n",
    "For every time step, we let the smoke advect in the velocity field and add new smoke through the inflow. Then the velocity field (composed of the previous wind and Brownian external noise) is self advected to get the next velocity field and finally the pressures are projected using the make incompressible function. \n",
    "The step function will be repeated to unroll the full plume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.examples.olfaction.simulate_plume_dataset import step\n",
    "\n",
    "# Run fluid dynamics simulation\n",
    "smoke_hist = []\n",
    "for i in trange(simulation_steps):\n",
    "    velocity, smoke = step(\n",
    "        velocity,\n",
    "        smoke,\n",
    "        wind_hist[i],\n",
    "        dt=dt,\n",
    "        inflow=inflow,\n",
    "        noise_magnitude=(0.5, 100.0),\n",
    "    )\n",
    "    smoke_vals = smoke.values.numpy(\"y,x\")\n",
    "    smoke_hist.append(smoke_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our time steps are much larger than that of the NeuroMechFly physics simulation, we interpolate the smoke field. This is much faster than running the plume simulation with smaller time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "sim_timepoints = np.arange(0, simulation_time, step=dt)\n",
    "smoke_hist_interp_fun = interp1d(sim_timepoints, smoke_hist, axis=0)\n",
    "\n",
    "new_timepoints = np.linspace(0, simulation_time - dt, num=10000)\n",
    "smoke_hist_interp = smoke_hist_interp_fun(new_timepoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the velocity field, the smoke density, and the inflow at the end of the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot(velocity, title=\"Wind velocity\", size=(5, 4))\n",
    "plt.gcf().savefig(output_dir / \"wind_velocity_tf.png\")\n",
    "\n",
    "fig = vis.plot(smoke, title=\"Smoke density\", size=(5, 4), show_color_bar=False)\n",
    "plt.gcf().savefig(output_dir / \"smoke_density_tf.png\")\n",
    "\n",
    "fig = vis.plot(inflow, title=\"Inflow\", size=(5, 4), show_color_bar=False)\n",
    "plt.gcf().savefig(output_dir / \"inflow_tf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this plume dataset in the HDF5 format. HDF5 is an efficient data format for saving arrays. Different from NumPy's built-in formats (NPY or NPZ), HDF5 allows partial reads of the dataset. In other words, with NPZ:\n",
    "\n",
    "```Python\n",
    "array = np.load(\"/path/to/file.npz\")  # this reads the whole array from disk to RAM\n",
    "\n",
    "for idx in my_iterator:\n",
    "    part = array[idx, :]  # further slicing of data simply takes portions of the array from RAM\n",
    "```\n",
    "\n",
    "... but with HDF5:\n",
    "\n",
    "```Python\n",
    "h5file = h5py.File(\"/path/to/file.hdf5\")  # this only loads the metadata; data stays on disk\n",
    "dataset = h5file[\"key\"]  # HDF5 datasets are NumPy-array-like and can be accessed the same way\n",
    "\n",
    "for idx in my_iterator:\n",
    "    part = dataset[idx, :]  # only now is the *specified portion* of data loaded into RAM\n",
    "```\n",
    "\n",
    "Therefore, at a slight cost of data loading overhead, we massively reduce the RAM usage of our program (only the plume state at the current time step is loaded into memory; the rest of the dataset remains on the hard disk). Although this does not make a practical difference in this tutorial, it become important if we want to run multiple long simulations in parallel. More information about the HDF5 data format can be found [here](https://docs.h5py.org/en/stable/quick.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(output_dir / \"plume.hdf5\", \"w\") as f:\n",
    "    f[\"plume\"] = np.stack(smoke_hist_interp).astype(np.float16)\n",
    "    f[\"inflow_pos\"] = inflow_pos\n",
    "    f[\"inflow_radius\"] = [inflow_radius]  # save as array with a single value\n",
    "    f[\"inflow_scaler\"] = [inflow_scaler]  # \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a plume within an arena\n",
    "\n",
    "The next step is to create an environment in which the fly can navigate the plume. For the sake of simplicity, here the pre-recorded plume is simply replayed and does not physically interact with the fly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OdorPlumeArena` class implements all the necessary functions to obtain sensory input from the plume and resample the plume to the size of the arena.\n",
    "In our plume simulation, the smoke grid has a spatial resolution of $\\Delta x_\\text{smoke} = 0.25$ units in an arena of size $(X_\\text{max}, Y_\\text{max})$ units. We allow the user to define how this grid is scaled to the physical arena using a dimensional scale parameter $s$: the size of the arena that the fly walks in is given by $s(X_\\text{max}, Y_\\text{max}) / \\Delta x_\\text{smoke}$ mm. For example, at $s=0.5$, the size of the arena is $0.5 \\times (80, 60) / 0.25 = (160, 120)$ mm. Similarly, the user can specify the speed at which the plume simulation is played out by setting the FPS of the plume dataset. These parameters are managed as follows:\n",
    "\n",
    "``` Python \n",
    "class OdorPlumeArena(BaseArena):\n",
    "    \"\"\"\n",
    "    This Arena class provides an interface to the separately simulated\n",
    "    odor plume. The plume simulation is stored in an HDF5 file. In this\n",
    "    class, we implement logics that calculate the intensity of the odor\n",
    "    at the fly's location at the correct time.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            plume_data_path: Path,\n",
    "            main_camera_name: str,\n",
    "            dimension_scale_factor: float = 0.5,\n",
    "            plume_simulation_fps: float = 200,\n",
    "            intensity_scale_factor: float = 1.0,\n",
    "            friction: Tuple[float, float, float] = (1, 0.005, 0.0001),\n",
    "            num_sensors: int = 4,\n",
    "        ):\n",
    "            \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            plume_data_path : Path\n",
    "                Path to the HDF5 file containing the plume simulation data.\n",
    "            main_camera_name : str\n",
    "                Name of the main camera used to render the plume simulation.\n",
    "            dimension_scale_factor : float, optional\n",
    "                Scaling factor for the plume simulation grid. Each cell in the\n",
    "                plume grid is this many millimeters in the simulation. By\n",
    "                default 0.5.\n",
    "            plume_simulation_fps : float, optional\n",
    "                Frame rate of the plume simulation. Each frame in the plume\n",
    "                dataset is ``1 / plume_simulation_fps`` seconds in the physics\n",
    "                simulation. By default 200.\n",
    "            intensity_scale_factor : float, optional\n",
    "                Scaling factor for the intensity of the odor. By default 1.0.\n",
    "            friction : Tuple[float, float, float], optional\n",
    "                Friction parameters for the floor geom. By default (1, 0.005,\n",
    "                0.0001).\n",
    "            num_sensors : int, optional\n",
    "                Number of olfactory sensors on the fly. By default 4.\n",
    "            \"\"\"\n",
    "\n",
    "            super().__init__()\n",
    "\n",
    "            self.dimension_scale_factor = dimension_scale_factor\n",
    "            self.plume_simulation_fps = plume_simulation_fps\n",
    "            self.intensity_scale_factor = intensity_scale_factor\n",
    "            self.friction = friction\n",
    "            self.num_sensors = num_sensors\n",
    "            self.curr_time = 0\n",
    "            self.plume_update_interval = 1 / plume_simulation_fps\n",
    "\n",
    "            # Load plume data\n",
    "            self.plume_dataset = h5py.File(plume_data_path, \"r\")\n",
    "            self.plume_grid = self.plume_dataset[\"plume\"]\n",
    "            self.arena_size = (\n",
    "                np.array(self.plume_grid.shape[1:][::-1]) * dimension_scale_factor\n",
    "            )\n",
    "\n",
    "            # Set up floor\n",
    "            floor_material = self.root_element.asset.add(\n",
    "                \"material\",\n",
    "                name=\"floor_material\",\n",
    "                reflectance=0.0,\n",
    "                shininess=0.0,\n",
    "                specular=0.0,\n",
    "                rgba=[0.6, 0.6, 0.6, 1],\n",
    "            )\n",
    "            self.root_element.worldbody.add(\n",
    "                \"geom\",\n",
    "                name=\"floor\",\n",
    "                type=\"box\",\n",
    "                size=(self.arena_size[0] / 2, self.arena_size[1], 1),\n",
    "                pos=(self.arena_size[0] / 2, self.arena_size[1] / 2, -1),\n",
    "                material=floor_material,\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also implement a function that reads out the odor intensity for every sensor from the simulated smoke grid:\n",
    "\n",
    "```Python \n",
    "def get_olfaction(self, antennae_pos: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the olfactory input for the given antennae positions. If\n",
    "        the fly is outside the plume simulation grid, returns np.nan.\n",
    "        \"\"\"\n",
    "        # get the current frame of the plume\n",
    "        frame_num = int(self.curr_time * self.plume_simulation_fps)\n",
    "        assert self.num_sensors == antennae_pos.shape[0]\n",
    "        intensities = np.zeros((self.odor_dimensions, self.num_sensors))\n",
    "        for i_sensor in range(self.num_sensors):\n",
    "            # get the sensor position in mm (from the physics)\n",
    "            x_mm, y_mm, _ = antennae_pos[i_sensor, :]\n",
    "            # map to our simulated plume dimensions\n",
    "            x_idx = int(x_mm / self.dimension_scale_factor)\n",
    "            y_idx = int(y_mm / self.dimension_scale_factor)\n",
    "            if (\n",
    "                x_idx < 0\n",
    "                or y_idx < 0\n",
    "                or x_idx >= self.plume_grid.shape[2]\n",
    "                or y_idx >= self.plume_grid.shape[1]\n",
    "            ):\n",
    "                intensities[0, i_sensor] = np.nan\n",
    "            else:\n",
    "                intensities[0, i_sensor] = self.plume_grid[frame_num, y_idx, x_idx]\n",
    "        return intensities * self.intensity_scale_factor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will implement a function to get the position mapping between the main_camera and indices in the simulated plume grid. This will become very handy when we want to project the simulated plume onto the arena for proper rendering.\n",
    " \n",
    "``` Python\n",
    "def get_position_mapping(\n",
    "        self, sim: Simulation\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Get the display location (row-col coordinates) of each pixel in\n",
    "        the fluid dynamics simulation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sim : Simulation\n",
    "            Simulation simulation object.\n",
    "        Returns\n",
    "        -------\n",
    "        pos_display: np.ndarray\n",
    "            Array of shape (n_row_pxls_plume, n_col_pxls_plume, 2)\n",
    "            containing the row-col coordinates of each plume simulation\n",
    "            cell on the **display** image (in pixels).\n",
    "        pos_physical: np.ndarray\n",
    "            Array of shape (n_row_pxls_plume, n_col_pxls_plume, 2)\n",
    "            containing the row-col coordinates of each plume simulation\n",
    "            cell on the **physical** simulated grid (in mm). This is a\n",
    "            regular lattice grid marking the physical position of the\n",
    "            *centers* of the fluid simulation cells.\n",
    "        \"\"\"\n",
    "        birdeye_cam_dm_control_obj = Camera(\n",
    "            sim.physics,\n",
    "            camera_id=self.main_camera_name,\n",
    "            width=sim.cameras[0].window_size[0],\n",
    "            height=sim.cameras[0].window_size[1],\n",
    "        )\n",
    "        camera_matrix = birdeye_cam_dm_control_obj.matrix\n",
    "        # Get the center of every grid cell\n",
    "        xs_physical, ys_physical = np.meshgrid(\n",
    "            np.arange(self.arena_size[0]) + 0.5,\n",
    "            np.arange(self.arena_size[1]) + 0.5,\n",
    "        )\n",
    "        # project those centers to the camera coordinates\n",
    "        xyz1_vecs = np.ones((xs_physical.size, 4))\n",
    "        xyz1_vecs[:, 0] = xs_physical.flatten()\n",
    "        xyz1_vecs[:, 1] = ys_physical.flatten()\n",
    "        xyz1_vecs[:, 2] = 0\n",
    "        pos_physical = xyz1_vecs[:, :2].reshape(*xs_physical.shape, 2)\n",
    "        xs_display, ys_display, display_scale = camera_matrix @ xyz1_vecs.T\n",
    "        xs_display /= display_scale\n",
    "        ys_display /= display_scale\n",
    "        pos_display = np.vstack((xs_display, ys_display))\n",
    "        pos_display = pos_display.T.reshape(*xs_physical.shape, 2)\n",
    "        return pos_display, pos_physical\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an `OdorPlumeArena` instance. For the sake of demonstration, we will use a dimensional scale factor of 0.25 and a very high plume FPS to make the simulation easier to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.examples.olfaction.plume_tracking_arena import OdorPlumeArena\n",
    "\n",
    "main_camera_name = \"birdeye_camera\"\n",
    "arena = OdorPlumeArena(\n",
    "    output_dir / \"plume.hdf5\", main_camera_name=main_camera_name,\n",
    "    plume_simulation_fps=8000, dimension_scale_factor=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to implement the main simulation loop. We will make the fly stand still for the sake of this demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym import Fly, SingleFlySimulation, Camera\n",
    "from flygym.examples.locomotion import PreprogrammedSteps\n",
    "\n",
    "timestep = 1e-4\n",
    "run_time = 1.0\n",
    "\n",
    "# Initialize fly simulation\n",
    "fly = Fly(\n",
    "    enable_olfaction=True,\n",
    "    spawn_pos=(60.0, 30.0, 0.25),\n",
    "    spawn_orientation=(0, 0, -np.pi / 2),\n",
    ")\n",
    "cam_params = {\"mode\":\"fixed\",\n",
    "    \"pos\": (\n",
    "                0.50 * arena.arena_size[0],\n",
    "                0.15 * arena.arena_size[1],\n",
    "                1.00 * arena.arena_size[1],\n",
    "            ),\n",
    "    \"euler\":(np.deg2rad(15), 0, 0), \"fovy\":60}\n",
    "    \n",
    "cam = Camera(\n",
    "    attachment_point=arena.root_element.worldbody,\n",
    "    camera_name=main_camera_name,\n",
    "    timestamp_text = False,\n",
    "    camera_parameters=cam_params\n",
    ")\n",
    "sim = SingleFlySimulation(fly=fly, arena=arena, cameras=[cam])\n",
    "\n",
    "preprogrammed_step = PreprogrammedSteps()\n",
    "standing_joint_angles = []\n",
    "\n",
    "for leg in preprogrammed_step.legs:\n",
    "    standing_joint_angles.extend(preprogrammed_step.get_joint_angles(leg, 0.0))\n",
    "\n",
    "target_num_steps = int(run_time / timestep)\n",
    "obs_list = []\n",
    "\n",
    "for i in trange(target_num_steps):\n",
    "    (obs, reward, terminated, truncated, info) = sim.step(\n",
    "        action={\"joints\": standing_joint_angles}\n",
    "    )\n",
    "    obs_list.append(obs)\n",
    "    sim.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the time series of the odor intensities sensed by the fly's olfactory sensory organs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odor_intensities = np.array([obs[\"odor_intensity\"] for obs in obs_list])\n",
    "time = np.arange(0, run_time, timestep)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4), tight_layout=True)\n",
    "\n",
    "lines = ax.plot(time, odor_intensities.squeeze(), lw=1)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Odor intensity (a.u.)\")\n",
    "ax.set_title(\"Odor intensity sensed by the fly\")\n",
    "\n",
    "ax.legend(lines, [sensor.name.split(\"_\")[0] for sensor in fly._antennae_sensors])\n",
    "fig.savefig(output_dir / \"odor_intensity_ts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate a video of the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.save_video(output_dir / \"sim_static.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we don't see the plume here! This is because we are simply reading out the appropriate values from the pre-generated plume dataset. The odor is not actually added or visualized in any way in the NeuroMechFly physics simulation. In the next section, we will build another layer of abstraction that overlays the image of the plume onto the rendered image for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plume tracking task\n",
    "\n",
    "By now, we have implemented an odor plume arena that replays the simulated plume. The fly can walk in this arena and experience intermittent bursts of odor. We will now implement a wrapper for the plume tracking task. In this layer of abstraction, we will implement the following functionalities:\n",
    "\n",
    "1. Overlay the plume on top of the rendered image.\n",
    "2. Truncate the simulation when the fly walks out of bound.\n",
    "\n",
    "Recall [the construction of the Markov Decision Process (MDP)](https://neuromechfly.org/tutorials/gym_basics_and_kinematic_replay.html#markov-decision-process-mdp-and-the-gym-api). The task that we are implementing is the Task/Environment under the MPD framework. Therefore, it is an `Env` in the Gymnasium interface. We will extend the `HybridTurningController` environment for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the `__init__` method. Here, we use the `get_position_mapping` function that we have implemented for `OdorPlumeArena` to find the following for each element in the odor simulation grid:\n",
    "\n",
    "1. The row-column position of it on the image rendered by the camera.\n",
    "2. The x-y position, in mm, of the physical spot where the center of cell is on the smoke grid.\n",
    "\n",
    "Then, we will interpolate these points in 2D so that for every pixel displayed on the camera's output, we know which cell it corresponds to on the plume grid and what the x-y coordinates are in the physical arena.\n",
    "\n",
    "```Python\n",
    "class PlumeNavigationTask(HybridTurningController):\n",
    "    \"\"\"\n",
    "    A wrapper around the ``HybridTurningController`` that implements logics\n",
    "    and utilities related to plume tracking such as overlaying the plume\n",
    "    onto the rendered images. It also checks if the fly is within the plume\n",
    "    simulation grid and truncates the simulation accordingly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fly: Fly,\n",
    "        arena: OdorPlumeArena,\n",
    "        render_plume_alpha: float = 0.75,\n",
    "        intensity_display_vmax: float = 1.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        fly: Fly\n",
    "            The fly object to be used. See\n",
    "            ``flygym.example.locomotion.HybridTurningController``.\n",
    "        arena: OdorPlumeArena\n",
    "            The odor plume arena object to be used. Initialize it before\n",
    "            creating the ``PlumeNavigationTask`` object.\n",
    "        render_plume_alpha : float\n",
    "            The transparency of the plume overlay on the rendered images.\n",
    "        intensity_display_vmax : float\n",
    "            The maximum intensity value to be displayed on the rendered\n",
    "            images.\n",
    "        \"\"\"\n",
    "        super().__init__(fly=fly, arena=arena, **kwargs)\n",
    "        self.arena = arena\n",
    "        self._plume_last_update_time = -np.inf\n",
    "        self._cached_plume_img = None\n",
    "        self._render_plume_alpha = render_plume_alpha\n",
    "        self._intensity_display_vmax = intensity_display_vmax\n",
    "\n",
    "        # Find out where on the displayed images the plume simulation grid\n",
    "        # should be overlaid. In other words, interpolate the mapping from\n",
    "        # displayed pixel positions to simulated physical positions.\n",
    "        pos_display_sample, pos_physical_sample = self.arena.get_position_mapping(self)\n",
    "        pos_display_sample = pos_display_sample.reshape(-1, 2)\n",
    "        pos_physical_sample = pos_physical_sample.reshape(-1, 2)\n",
    "        interp = LinearNDInterpolator(\n",
    "            pos_display_sample, pos_physical_sample, fill_value=np.nan\n",
    "        )\n",
    "        xs_display, ys_display = np.meshgrid(\n",
    "            np.arange(self.cameras[0].window_size[0]),\n",
    "            np.arange(self.cameras[0].window_size[1]),\n",
    "        )\n",
    "        pos_display_all = np.vstack([xs_display.flatten(), ys_display.flatten()]).T\n",
    "        pos_physical_all = interp(pos_display_all)\n",
    "        pos_physical_all = pos_physical_all.reshape(\n",
    "            *self.cameras[0].window_size[::-1], 2\n",
    "        )\n",
    "        grid_idx_all = pos_physical_all / self.arena.dimension_scale_factor\n",
    "        grid_idx_all[np.isnan(grid_idx_all)] = -1\n",
    "        # self.grid_idx_all has the shape (cam_nrows, cam_ncols, 2) and\n",
    "        # indicates the (x, y) indices of the plume simulation grid cell.\n",
    "        # When the index is -1, this point on the displayed image is out of\n",
    "        # the simulated arena.\n",
    "        self.grid_idx_all = grid_idx_all.astype(np.int16)\n",
    "\n",
    "        self.focus_cam = self.cameras[1] if len(self.cameras) > 1 else None\n",
    "        if self.focus_cam is not None:\n",
    "            self.fc_width, self.fc_height = self.focus_cam.window_size\n",
    "            pixel_meshgrid = np.meshgrid(\n",
    "                np.arange(self.fc_width), np.arange(self.fc_height)\n",
    "            )\n",
    "            self.pixel_idxs = np.stack(\n",
    "                [pixel_meshgrid[0].flatten(), pixel_meshgrid[1].flatten()], axis=1\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To override the `render` method, we just need to get the plume image corresponding to the current time point and overlay it on top of the camera image. We also add a bar indicating the mean intensity to the bottom image for better visualization.\n",
    "\n",
    "```Python\n",
    "def render(self, *args, **kwargs):\n",
    "    rendered_img = super().render(*args, **kwargs)[0]\n",
    "    if rendered_img is None:\n",
    "        return [rendered_img]  # no image rendered\n",
    "\n",
    "    # Overlay plume\n",
    "    time_since_last_update = self.curr_time - self._plume_last_update_time\n",
    "    update_needed = time_since_last_update > self.arena.plume_update_interval\n",
    "    if update_needed or self._cached_plume_img is None:\n",
    "        t_idx = int(self.curr_time * self.arena.plume_simulation_fps)\n",
    "        self._cached_plume_img = _resample_plume_image(\n",
    "            self.grid_idx_all, self.arena.plume_grid[t_idx, :, :].astype(np.float32)\n",
    "        )\n",
    "        self._plume_last_update_time = self.curr_time\n",
    "    plume_img = self._cached_plume_img[:, :, np.newaxis] * self._render_plume_alpha\n",
    "    plume_img[np.isnan(plume_img)] = 0\n",
    "    rendered_img = np.clip(rendered_img - plume_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Add intensity indicator\n",
    "    mean_intensity = self.get_observation()[\"odor_intensity\"].mean()\n",
    "    mean_intensity_relative = np.clip(\n",
    "        mean_intensity / self._intensity_display_vmax, 0, 1\n",
    "    )\n",
    "    rmin = self.cameras[0].window_size[1] - 10\n",
    "    rmax = self.cameras[0].window_size[1]\n",
    "    cmin = 0\n",
    "    cmax = int(self.cameras[0].window_size[0] * mean_intensity_relative)\n",
    "    rendered_img[rmin:rmax, cmin:cmax] = (255, 0, 0)\n",
    "\n",
    "    # Replace recorded image with modified one\n",
    "    self.cameras[0]._frames[-1] = rendered_img\n",
    "    return [rendered_img]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just define a fly, an arena and a camera to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual `_resample_plume_image` function is accelerated with [Numba](https://numba.pydata.org/). This is because we need to iterate every pixel to modify its value, and loops in native, uncompiled Python [are extremely slow](https://stackoverflow.com/questions/8097408/why-python-is-so-slow-for-a-simple-for-loop). With Numba's `njit` [decorator](https://peps.python.org/pep-0318/), we can compile the Python code into LLVM — a low-level code that directly interfaces with the CPU through backends — just in time (hence the \"JIT\" in `njit`). Furthermore, we will force Numba to do this in a \"no-Python\" way (hence the \"N\" in `njit`) to ensure fast execution. These changes give us C-like performance in the render function.\n",
    "\n",
    "``` Python \n",
    "from numba import njit\n",
    "\n",
    "@njit(parallel=True)\n",
    "def _resample_plume_image(grid_idx_all, plume_grid):\n",
    "    plume_img = np.zeros(grid_idx_all.shape[:2])\n",
    "    for i in prange(grid_idx_all.shape[0]):\n",
    "        for j in prange(grid_idx_all.shape[1]):\n",
    "            x_idx = grid_idx_all[i, j, 0]\n",
    "            y_idx = grid_idx_all[i, j, 1]\n",
    "            if x_idx != -1:\n",
    "                plume_img[i, j] = plume_grid[y_idx, x_idx]\n",
    "    return plume_img\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To truncate the simulation when the fly moves out of bounds, we can simply set the `truncate` flag — returned by the `step` method of any Gymnasium environment — to `True`. Recall that we have already implemented a logic in the `OdorPlumeArena` that returns NaN when the queried position is out of bounds. Therefore,\n",
    "\n",
    "```Python\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "        if np.isnan(obs[\"odor_intensity\"]).any():\n",
    "            truncated = True\n",
    "        return obs, reward, terminated, truncated, info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a sample simulation where the fly walks blindly forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.examples.olfaction.plume_tracking_task import PlumeNavigationTask\n",
    "\n",
    "arena = OdorPlumeArena(\n",
    "    output_dir / \"plume.hdf5\", main_camera_name=main_camera_name,\n",
    "    plume_simulation_fps=8000, dimension_scale_factor=0.25\n",
    ")\n",
    "\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "fly = Fly(\n",
    "    enable_adhesion=True,\n",
    "    draw_adhesion=True,\n",
    "    enable_olfaction=True,\n",
    "    enable_vision=False,\n",
    "    contact_sensor_placements=contact_sensor_placements,\n",
    "    spawn_pos=(60.0, 30.0, 0.25),\n",
    "    spawn_orientation=(0, 0, -np.pi / 2),\n",
    ")\n",
    "cam_params = {\"mode\":\"fixed\",\n",
    "    \"pos\": (\n",
    "                0.50 * arena.arena_size[0],\n",
    "                0.15 * arena.arena_size[1],\n",
    "                1.00 * arena.arena_size[1],\n",
    "            ),\n",
    "    \"euler\":(np.deg2rad(15), 0, 0), \"fovy\":60}\n",
    "    \n",
    "cam = Camera(\n",
    "    attachment_point=arena.root_element.worldbody,\n",
    "    camera_name=main_camera_name,\n",
    "    timestamp_text = False,\n",
    "    camera_parameters=cam_params\n",
    ")\n",
    "\n",
    "sim = PlumeNavigationTask(\n",
    "    fly=fly,\n",
    "    arena=arena,\n",
    "    cameras=[cam],\n",
    ")\n",
    "\n",
    "sim.reset(0)\n",
    "\n",
    "straight_dn_drive = np.array([1.0, 1.0])\n",
    "for i in trange(target_num_steps):\n",
    "    obs, reward, terminated, truncated, info = sim.step(straight_dn_drive)\n",
    "    sim.render()\n",
    "\n",
    "cam.save_video(output_dir / \"plume_display.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a plume tracking controller\n",
    "\n",
    "Having implemented the MDP task for plume tracking, we are finally ready to build a plume following controller. We propose a model where the fly walks crosswind when little odor evidence is accumulated and upwind when encountering a lot of odor packets. The crosswind direction is random and biased by the encounter history during crosswind walks.\n",
    "\n",
    "It takes time for the first plume burst to reach the fly. We will crop the first half of the plume simulation so that the plume reaches the fly immediately. This is merely to shorten the simulation in this tutorial and is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cropped_plume = smoke_hist_interp[1000:]\n",
    "\n",
    "# lets crop a few frames from the plume simulation\n",
    "with h5py.File(output_dir / \"plume_tcropped.hdf5\", \"w\") as f:\n",
    "    f[\"plume\"] = np.stack(time_cropped_plume).astype(np.float16)\n",
    "    f[\"inflow_pos\"] = inflow_pos\n",
    "    f[\"inflow_radius\"] = inflow_radius\n",
    "    f[\"inflow_scaler\"] = inflow_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the plume navigation controller as follows. Our controller accumulates odor evidence during a fixed interval of time. The accumulated evidence increases with odor encounters and decreases with time. From accumulated evidence, we derive the angle of wind direction. The more evidence accumulated, the more likely it is that the fly will head upwind. It heads more randomly, i.e., more crosswind, when no evidence is accumulated. When the target angle is defined, the descending drive is regularly updated to match the target angle. See [Demir et al, 2020](https://doi.org/10.7554/eLife.57524) or our NeuroMechFly v2 paper for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import cv2\n",
    "from flygym.util import get_data_path\n",
    "\n",
    "\n",
    "class WalkingState(Enum):\n",
    "    FORWARD = 0\n",
    "    TURN_LEFT = 1\n",
    "    TURN_RIGHT = 2\n",
    "    STOP = 3\n",
    "\n",
    "\n",
    "# get the angle of the vector in world coordinates\n",
    "def get_vector_angle(v):\n",
    "    return np.arctan2(v[1], v[0])\n",
    "\n",
    "\n",
    "# change an array to a set of probabilities (sum to 1)\n",
    "# this is used to bias crosswind walking\n",
    "def to_probability(x):\n",
    "    # the difference between the two values reflects\n",
    "    # the probability of each entry\n",
    "    x += np.abs(np.min(x)) + 1\n",
    "    return x / np.sum(x)\n",
    "\n",
    "\n",
    "class SimplePlumeNavigationController:\n",
    "    # defines a very simple controller to navigate the odor plume\n",
    "    def __init__(self, timestep, wind_dir=[-1.0, 0.0], seed=0):\n",
    "        self.timestep = timestep\n",
    "        self.wind_dir = wind_dir\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # define the dn drives for each state\n",
    "        self.dn_drives = {\n",
    "            WalkingState.FORWARD: np.array([1.0, 1.0]),\n",
    "            WalkingState.TURN_LEFT: np.array((-0.4, 1.2)),\n",
    "            WalkingState.TURN_RIGHT: np.array((1.2, -0.4)),\n",
    "            WalkingState.STOP: np.array((0.0, 0.0)),\n",
    "        }\n",
    "\n",
    "        # evidence acccumulation parameters\n",
    "        self.accumulated_evidence = 0.0\n",
    "        self.accumulation_decay = 0.0001\n",
    "        self.accumulation_odor_gain = 0.05\n",
    "        self.accumulation_threshold = 20.0\n",
    "\n",
    "        # decision making parameters\n",
    "        self.default_decision_interval = 0.75  # s\n",
    "        self.since_last_decision_time = 0.0\n",
    "\n",
    "        # minimal evidence value during a decision interval\n",
    "        self.min_evidence = (\n",
    "            -1 * self.accumulation_decay * self.default_decision_interval / timestep\n",
    "        )\n",
    "\n",
    "        # descending neuron drive parameters\n",
    "        self.dn_drive_update_interval = 0.1  # s\n",
    "        self.dn_drive_update_steps = int(self.dn_drive_update_interval / self.timestep)\n",
    "        self.dn_drive = self.dn_drives[WalkingState.STOP]\n",
    "\n",
    "        # controller state parameters\n",
    "        self.curr_state = WalkingState.STOP\n",
    "        self.target_angle = np.nan\n",
    "        self.to_upwind_angle = np.nan\n",
    "        self.upwind_success = [0, 0]\n",
    "\n",
    "        # boundary checking parameters\n",
    "        self.boundary_refractory_period = 1.0\n",
    "        self.boundary_time = 0.0\n",
    "\n",
    "    def get_target_angle(self):\n",
    "        \"\"\"\n",
    "        Get the target angle to the wind based on the accumulated evidence, the wind direction\n",
    "        and the history of success in the crosswind direction\n",
    "        The target angle is more upwind if the accumulated evidence is high\n",
    "        and more crosswind if the accumulated evidence is low\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        target_angle : float\n",
    "            The target angle to the wind (in radian)\n",
    "        to_upwind_angle : float\n",
    "            The angle to the upwind direction (in radian)\n",
    "        \"\"\"\n",
    "\n",
    "        up_wind_angle = get_vector_angle(self.wind_dir) - np.pi\n",
    "        # the angle to the wind is defined by the accumulated evidence:\n",
    "        #   - if little evidence, the fly will go crosswind (angle to upwind = np.pi/2)\n",
    "        #   - if a lots of evidence, the fly will go upwind (angle to upwind = 0)\n",
    "        to_upwind_angle = np.tanh(self.accumulated_evidence) * np.pi / 4 - np.pi / 4\n",
    "        crosswind_success_proba = to_probability(self.upwind_success)\n",
    "\n",
    "        # randomize the sign of the angle depending on the history of success\n",
    "        to_upwind_angle = np.random.choice([-1, 1], p=crosswind_success_proba) * np.abs(\n",
    "            to_upwind_angle\n",
    "        )\n",
    "\n",
    "        # compute the target angle (the up wind angle + the angle to upwind direction)\n",
    "        target_angle = up_wind_angle + to_upwind_angle\n",
    "        if target_angle > np.pi:\n",
    "            target_angle -= 2 * np.pi\n",
    "        elif target_angle < -np.pi:\n",
    "            target_angle += 2 * np.pi\n",
    "\n",
    "        return target_angle, to_upwind_angle\n",
    "\n",
    "    def angle_to_dn_drive(self, fly_orientation):\n",
    "        \"\"\"\n",
    "        Compare the fly's orientation to the target angle and return the\n",
    "        descending drive that will make the fly go in the correct direction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fly_orientation : np.array\n",
    "            The fly orientation vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dn_drive : np.array\n",
    "            The dn drive that will make the fly go in the correct direction\n",
    "        \"\"\"\n",
    "\n",
    "        fly_angle = get_vector_angle(fly_orientation)\n",
    "        angle_diff = self.target_angle - fly_angle\n",
    "        if angle_diff > np.pi:\n",
    "            angle_diff -= 2 * np.pi\n",
    "        elif angle_diff < -np.pi:\n",
    "            angle_diff += 2 * np.pi\n",
    "\n",
    "        if np.isnan(self.target_angle):\n",
    "            return self.dn_drives[WalkingState.STOP], WalkingState.STOP\n",
    "        elif angle_diff > np.deg2rad(10):\n",
    "            return self.dn_drives[WalkingState.TURN_LEFT], WalkingState.TURN_LEFT\n",
    "        elif angle_diff < -np.deg2rad(10):\n",
    "            return self.dn_drives[WalkingState.TURN_RIGHT], WalkingState.TURN_RIGHT\n",
    "        else:\n",
    "            return self.dn_drives[WalkingState.FORWARD], WalkingState.FORWARD\n",
    "\n",
    "    def step(self, fly_orientation, odor_intensities, close_to_boundary, curr_time):\n",
    "        \"\"\"\n",
    "        Step the controller:\n",
    "          - Check if the fly is close to the boundary\n",
    "          - Accumulate evidence\n",
    "          - Update the target angle if:\n",
    "            - the accumulated evidence is high\n",
    "            - the decision interval is reached\n",
    "            - the fly is close to the boundary\n",
    "          - Update the success history:\n",
    "            - If crosswind: update the success history (increases if\n",
    "              the fly collected evidence in that direction, decreases otherwise)\n",
    "            - If close to boundary and the fly is not upwind: decrease success history\n",
    "          - Update the descending drive\n",
    "          - Increment time and counters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fly_orientation : np.array\n",
    "            The fly orientation vector\n",
    "        odor_intensities : np.array\n",
    "            The odor intensities collected by the fly\n",
    "        close_to_boundary : bool\n",
    "            Whether the fly is close to the boundary\n",
    "        curr_time : float\n",
    "            The current time of the simulation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dn_drive : np.array\n",
    "            The dn drive that will make the fly go in the correct direction\n",
    "        \"\"\"\n",
    "\n",
    "        if self.boundary_time > 0.0:\n",
    "            self.boundary_time += self.timestep\n",
    "        elif self.boundary_time > self.boundary_refractory_period:\n",
    "            self.boundary_time = 0.0\n",
    "\n",
    "        boundary_inv = close_to_boundary and self.boundary_time == 0.0\n",
    "\n",
    "        if (\n",
    "            self.accumulated_evidence > self.accumulation_threshold\n",
    "            or self.since_last_decision_time > self.default_decision_interval\n",
    "            or boundary_inv\n",
    "        ):\n",
    "            if self.accumulated_evidence > self.accumulation_threshold:\n",
    "                # reset the history and just take into account the last success\n",
    "                self.upwind_success = [0, 0]\n",
    "\n",
    "            if boundary_inv:\n",
    "                # if close to the boundary and not upwind\n",
    "                # decrease the success history of the correct directions as it led the\n",
    "                # fly to the boundary\n",
    "                if self.to_upwind_angle < np.deg2rad(-45):\n",
    "                    self.upwind_success[0] -= 10\n",
    "                elif self.to_upwind_angle > np.deg2rad(45):\n",
    "                    self.upwind_success[1] -= 10\n",
    "                self.boundary_time += self.timestep\n",
    "            else:\n",
    "                # else update the success history if crosswind and\n",
    "                # the fly collected evidence in that direction\n",
    "                # increase the success history\n",
    "                if self.to_upwind_angle < np.deg2rad(-45):\n",
    "                    self.upwind_success[0] += (\n",
    "                        1 if self.accumulated_evidence > self.min_evidence else -1\n",
    "                    )\n",
    "                elif self.to_upwind_angle > np.deg2rad(45):\n",
    "                    self.upwind_success[1] += (\n",
    "                        1 if self.accumulated_evidence > self.min_evidence else -1\n",
    "                    )\n",
    "\n",
    "            # reset counters\n",
    "            self.target_angle, self.to_upwind_angle = self.get_target_angle()\n",
    "            self.accumulated_evidence = 0.0\n",
    "            self.since_last_decision_time = 0.0\n",
    "        else:\n",
    "            # update the accumulated evidence\n",
    "            self.accumulated_evidence += (\n",
    "                odor_intensities.sum() * self.accumulation_odor_gain\n",
    "                - self.accumulation_decay\n",
    "            )\n",
    "        if (\n",
    "            np.rint(curr_time / self.timestep) % self.dn_drive_update_steps == 0\n",
    "            or boundary_inv\n",
    "        ):\n",
    "            # §update the dn drive\n",
    "            self.dn_drive, self.curr_state = self.angle_to_dn_drive(fly_orientation)\n",
    "\n",
    "        self.since_last_decision_time += self.timestep\n",
    "\n",
    "        return self.dn_drive\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        \"\"\"\n",
    "        Reset all the counters and parameters of the controller\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "            The random seed to use for the controller\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.accumulated_evidence = 0.0\n",
    "        self.since_last_decision_time = 0.0\n",
    "        self.upwind_success = [0, 0]\n",
    "        self.boundary_time = 0.0\n",
    "        self.target_angle = np.nan\n",
    "        self.to_upwind_angle = np.nan\n",
    "        self.curr_state = WalkingState.STOP\n",
    "        self.dn_drive = self.dn_drives[self.curr_state]\n",
    "\n",
    "\n",
    "def get_debug_str(\n",
    "    accumulated_evidence, curr_angle, target_angle, crosswind_success_proba\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a string that represents the state of the controller\n",
    "    \"\"\"\n",
    "    crosswind_success_proba_str = \" \".join(\n",
    "        [f\"{co:.2f}\" for co in crosswind_success_proba]\n",
    "    )\n",
    "    return [\n",
    "        f\"Accumulated evidence: {accumulated_evidence:.2f}\",\n",
    "        f\"Fly orientation: {np.rad2deg(curr_angle):.2f}\",\n",
    "        f\"Target angle: {np.rad2deg(target_angle):.2f}\",\n",
    "        f\"Crosswind success proba: {crosswind_success_proba_str}\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_walking_icons():\n",
    "    \"\"\"\n",
    "    Get all icons representing the walking directions\n",
    "    \"\"\"\n",
    "    icons_dir = get_data_path(\"flygym\", \"data\") / \"etc/locomotion_icons\"\n",
    "    icons = {}\n",
    "    for key in [\"forward\", \"left\", \"right\", \"stop\"]:\n",
    "        icon_path = icons_dir / f\"{key}.png\"\n",
    "        icons[key] = cv2.imread(str(icon_path), cv2.IMREAD_UNCHANGED)\n",
    "    return {\n",
    "        WalkingState.FORWARD: icons[\"forward\"],\n",
    "        WalkingState.TURN_LEFT: icons[\"left\"],\n",
    "        WalkingState.TURN_RIGHT: icons[\"right\"],\n",
    "        WalkingState.STOP: icons[\"stop\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def get_inflow_circle(inflow_pos, inflow_radius, camera_matrix):\n",
    "    \"\"\"\n",
    "    Compute the xy locations of the inflow circle in the camera view\n",
    "    \"\"\"\n",
    "    # draw a circle around the inflow position (get x y pos of\n",
    "    # a few points on the circle)\n",
    "    circle_x, circle_y = [], []\n",
    "    for angle in np.linspace(0, 2 * np.pi + 0.01, num=50):\n",
    "        circle_x.append(inflow_pos[0] + inflow_radius * np.cos(angle))\n",
    "        circle_y.append(inflow_pos[1] + inflow_radius * np.sin(angle))\n",
    "\n",
    "    xyz_global = np.array([circle_x, circle_y, np.zeros_like(circle_x)])\n",
    "\n",
    "    # project those points on the camera view\n",
    "    # Camera matrices multiply homogenous [x, y, z, 1] vectors.\n",
    "    corners_homogeneous = np.ones((4, xyz_global.shape[1]), dtype=float)\n",
    "    corners_homogeneous[:3, :] = xyz_global\n",
    "\n",
    "    # Project world coordinates into pixel space. See:\n",
    "    # https://en.wikipedia.org/wiki/3D_projection#Mathematical_formula\n",
    "    xs, ys, s = camera_matrix @ corners_homogeneous\n",
    "\n",
    "    # x and y are in the pixel coordinate system.\n",
    "    x = np.rint(xs / s).astype(int)\n",
    "    y = np.rint(ys / s).astype(int)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def render_overlay(\n",
    "    rendered_img,\n",
    "    accumulated_evidence,\n",
    "    fly_orientation,\n",
    "    target_angle,\n",
    "    crosswind_success_proba,\n",
    "    icon,\n",
    "    window_size,\n",
    "    inflow_x,\n",
    "    inflow_y,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to modify the simulation rendered images\n",
    "    \"\"\"\n",
    "\n",
    "    if rendered_img is not None:\n",
    "        sub_strings = get_debug_str(\n",
    "            accumulated_evidence,\n",
    "            get_vector_angle(fly_orientation),\n",
    "            target_angle,\n",
    "            crosswind_success_proba,\n",
    "        )\n",
    "        # put string at the top left corner of the image\n",
    "        for j, sub_string in enumerate(sub_strings):\n",
    "            rendered_img = cv2.putText(\n",
    "                rendered_img,\n",
    "                sub_string,\n",
    "                (5, window_size[1] - (len(sub_strings) - j + 1) * 15),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.4,\n",
    "                (0, 0, 0),\n",
    "                1,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        # put the icon just under the debug string\n",
    "        rendered_img[\n",
    "            window_size[1] - 100 - icon.shape[1] : window_size[1] - 100,\n",
    "            0 : icon.shape[1],\n",
    "            :,\n",
    "        ] = icon\n",
    "\n",
    "        # draw the inflow circle as a free line\n",
    "        rendered_img = cv2.polylines(\n",
    "            rendered_img,\n",
    "            [np.array([list(zip(inflow_x, inflow_y))])],\n",
    "            isClosed=True,\n",
    "            color=(255, 0, 0),\n",
    "            thickness=2,\n",
    "        )\n",
    "\n",
    "    return rendered_img\n",
    "\n",
    "\n",
    "def is_close_to_boundary(pos, arena_size, margin=5.0):\n",
    "    \"\"\"\n",
    "    Check if the fly is close to the boundary\n",
    "\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pos[0] < margin\n",
    "        or pos[0] > arena_size[0] - margin\n",
    "        or pos[1] < margin\n",
    "        or pos[1] > arena_size[1] - margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run this controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dm_control.mujoco import Camera as DmCamera\n",
    "\n",
    "# write the same loop as before but with the new controller\n",
    "timestep = 1e-4\n",
    "run_time = 10.0\n",
    "\n",
    "np.random.seed(0)\n",
    "arena = OdorPlumeArena(\n",
    "    output_dir / \"plume_tcropped.hdf5\",\n",
    "    main_camera_name=main_camera_name,\n",
    "    plume_simulation_fps=800,\n",
    "    dimension_scale_factor=0.25,\n",
    ")\n",
    "\n",
    "# Define the fly\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "fly = Fly(\n",
    "    enable_adhesion=True,\n",
    "    draw_adhesion=True,\n",
    "    enable_olfaction=True,\n",
    "    enable_vision=False,\n",
    "    contact_sensor_placements=contact_sensor_placements,\n",
    "    # Here the opposite spawn position can be tried (65.0, 15.0, 0.25)\n",
    "    spawn_pos=(65.0, 45.0, 0.25),\n",
    "    spawn_orientation=(0, 0, -np.pi / 2),\n",
    ")\n",
    "\n",
    "wind_dir = [1.0, 0.0]\n",
    "ctrl = SimplePlumeNavigationController(timestep, wind_dir=wind_dir)\n",
    "\n",
    "cam_params = {\"mode\":\"fixed\",\n",
    "    \"pos\": (\n",
    "                0.50 * arena.arena_size[0],\n",
    "                0.15 * arena.arena_size[1],\n",
    "                1.00 * arena.arena_size[1],\n",
    "            ),\n",
    "    \"euler\":(np.deg2rad(15), 0, 0), \"fovy\":60}\n",
    "    \n",
    "cam = Camera(\n",
    "    attachment_point=arena.root_element.worldbody,\n",
    "    camera_name=main_camera_name,\n",
    "    timestamp_text = False,\n",
    "    camera_parameters=cam_params\n",
    ")\n",
    "\n",
    "dm_cam = DmCamera(\n",
    "    sim.physics,\n",
    "    camera_id=cam.camera_id,\n",
    "    width=cam.window_size[0],\n",
    "    height=cam.window_size[1],\n",
    ")\n",
    "camera_matrix = dm_cam.matrix\n",
    "arena_inflow_pos = np.array(inflow_pos) / arena.dimension_scale_factor * smoke_grid_size\n",
    "target_inflow_radius = 5.0\n",
    "inflow_x, inflow_y = get_inflow_circle(\n",
    "    arena_inflow_pos,\n",
    "    target_inflow_radius,\n",
    "    camera_matrix,\n",
    ")\n",
    "\n",
    "sim = PlumeNavigationTask(\n",
    "    fly=fly,\n",
    "    arena=arena,\n",
    "    cameras=[cam],\n",
    ")\n",
    "\n",
    "walking_icons = get_walking_icons()\n",
    "\n",
    "obs, info = sim.reset(0)\n",
    "\n",
    "for i in trange(np.rint(run_time / timestep).astype(int)):\n",
    "    fly_orientation = obs[\"fly_orientation\"][:2]\n",
    "    fly_orientation /= np.linalg.norm(fly_orientation)\n",
    "    close_to_boundary = is_close_to_boundary(obs[\"fly\"][0][:2], arena.arena_size)\n",
    "    dn_drive = ctrl.step(\n",
    "        fly_orientation, obs[\"odor_intensity\"], close_to_boundary, sim.curr_time\n",
    "    )\n",
    "\n",
    "    obs, reward, terminated, truncated, info = sim.step(dn_drive)\n",
    "\n",
    "    icon = walking_icons[ctrl.curr_state][:, :, :3]\n",
    "    rendered_img = sim.render()[0]\n",
    "    rendered_img = render_overlay(\n",
    "        rendered_img,\n",
    "        ctrl.accumulated_evidence,\n",
    "        fly_orientation,\n",
    "        ctrl.target_angle,\n",
    "        to_probability(ctrl.upwind_success),\n",
    "        icon,\n",
    "        cam.window_size,\n",
    "        inflow_x,\n",
    "        inflow_y,\n",
    "    )\n",
    "\n",
    "    if rendered_img is not None:\n",
    "        cam._frames[-1] = rendered_img\n",
    "\n",
    "    if np.linalg.norm(obs[\"fly\"][0][:2] - arena_inflow_pos) < target_inflow_radius:\n",
    "        print(\"The fly reached the inflow\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"The fly went out of bound\")\n",
    "        break\n",
    "\n",
    "    obs_list.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.save_video(output_dir / \"plume_navigation_controller.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
