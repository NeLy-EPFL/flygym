{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head stabilization\n",
    "\n",
    "**Author:** Sibo Wang-Chen\n",
    "\n",
    "**Note:** The code presented in this notebook has been simplified and restructured for display in a notebook format. A more complete and better structured implementation can be found in the [examples folder of the FlyGym repository on GitHub](https://github.com/NeLy-EPFL/flygym/tree/main/flygym/examples/).\n",
    "\n",
    "**Summary:** In this tutorial, we will use mechanosensory information to correct for self motion in closed loop. We will train an internal model that predicts the appropriate neck actuation signals, based on leg joint angles and ground contacts, to minimize head rotations during walking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the [previous tutorial](https://neuromechfly.org/tutorials/path_integration.html), we demonstrated how one can integrate ascending mechanosensory information to estimate the fly's position. In this tutorial, we will demonstrate another way in which the fly uses ascending motor signals to complete the sensorimotor control loop.\n",
    "\n",
    "In flies, head stabilization has been shown to be used to compensate for body pitch and roll ([Kress & Egelhaaf, 2012](https://doi.org/10.1242/jeb.066910)) during locomotion. It is thought that these stabilizing movements may be informed by leg sensory feedback signals ([Gollin & Dürr, 2018](https://doi.org/10.1007/978-3-319-95972-6_20)). To explore head stabilization in our embodied model, we will design a controller in which leg joint angles (i.e., proprioceptive signals, 6 legs × 7 degrees of freedom per leg) and ground contacts (i.e., tactile signals, 6 legs) are given as inputs to a multilayer perceptron (MLP). This model, in turn, predicts the appropriate head roll and pitch required to cancel visual rotations caused by the animal's own body movements during walking. We will use these signals to actuate the neck joint and aim to dampen head rotation. This approach is illustrated as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/NeLy-EPFL/_media/blob/main/flygym/head_stabilization/head_stabilization_schematic.png?raw=true\" alt=\"head_stabilization_schematic.png\" width=\"700\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting training data\n",
    "\n",
    "We start by running short simulations of walking while recording joint angles, ground contacts, and head rotations. This will give us a set of input-output pairs to use as training data. To run the simulations, we implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from tqdm import trange\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from dm_control.utils import transformations\n",
    "from dm_control.rl.control import PhysicsError\n",
    "\n",
    "from flygym import Fly, ZStabilizedCamera\n",
    "from flygym.arena import FlatTerrain, BlocksTerrain\n",
    "from flygym.preprogrammed import get_cpg_biases\n",
    "from flygym.examples.locomotion import HybridTurningController\n",
    "\n",
    "\n",
    "def run_simulation(\n",
    "    gait: str = \"tripod\",\n",
    "    terrain: str = \"flat\",\n",
    "    spawn_xy: tuple[float, float] = (0, 0),\n",
    "    dn_drive: tuple[float, float] = (1, 1),\n",
    "    sim_duration: float = 0.5,\n",
    "    enable_rendering: bool = False,\n",
    "    live_display: bool = False,\n",
    "    output_dir: Optional[Path] = None,\n",
    "    pbar: bool = False,\n",
    "):\n",
    "    \"\"\"Simulate locomotion and collect proprioceptive information to train\n",
    "    a neural network for head stabilization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gait : str, optional\n",
    "        The type of gait for the fly. Choose from ['tripod', 'tetrapod',\n",
    "        'wave']. Defaults to \"tripod\".\n",
    "    terrain : str, optional\n",
    "        The type of terrain for the fly. Choose from ['flat', 'blocks'].\n",
    "        Defaults to \"flat\".\n",
    "    spawn_xy : tuple[float, float], optional\n",
    "        The x and y coordinates of the fly's spawn position. Defaults to\n",
    "        (0, 0).\n",
    "    dn_drive : tuple[float, float], optional\n",
    "        The DN drive values for the left and right wings. Defaults to\n",
    "        (1, 1).\n",
    "    sim_duration : float, optional\n",
    "        The duration of the simulation in seconds. Defaults to 0.5.\n",
    "    enable_rendering: bool, optional\n",
    "        If True, enables rendering. Defaults to False.\n",
    "    live_display : bool, optional\n",
    "        If True, enables live display. Defaults to False.\n",
    "    output_dir : Path, optional\n",
    "        The directory to which output files are saved. Defaults to None.\n",
    "    pbar : bool, optional\n",
    "        If True, enables progress bar. Defaults to False.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised when an unknown terrain type is provided.\n",
    "    \"\"\"\n",
    "    if (not enable_rendering) and live_display:\n",
    "        raise ValueError(\"Cannot enable live display without rendering.\")\n",
    "\n",
    "    # Set up arena\n",
    "    if terrain == \"flat\":\n",
    "        arena = FlatTerrain()\n",
    "    elif terrain == \"blocks\":\n",
    "        arena = BlocksTerrain(height_range=(0.2, 0.2))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown terrain type: {terrain}\")\n",
    "\n",
    "    # Set up simulation\n",
    "    contact_sensor_placements = [\n",
    "        f\"{leg}{segment}\"\n",
    "        for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "        for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "    ]\n",
    "    fly = Fly(\n",
    "        enable_adhesion=True,\n",
    "        draw_adhesion=True,\n",
    "        detect_flip=True,\n",
    "        contact_sensor_placements=contact_sensor_placements,\n",
    "        spawn_pos=(*spawn_xy, 0.25),\n",
    "    )\n",
    "    cam = ZStabilizedCamera(\n",
    "        attachment_point=fly.model.worldbody,\n",
    "        camera_name=\"camera_left\",\n",
    "        attachment_name=fly.name,\n",
    "        targeted_fly_names=[fly.name],\n",
    "        play_speed=0.1,\n",
    "    )\n",
    "    sim = HybridTurningController(\n",
    "        arena=arena,\n",
    "        phase_biases=get_cpg_biases(gait),\n",
    "        fly=fly,\n",
    "        cameras=[cam],\n",
    "        timestep=1e-4,\n",
    "    )\n",
    "\n",
    "    # Main simulation loop\n",
    "    obs, info = sim.reset(0)\n",
    "    obs_hist, info_hist, action_hist = [], [], []\n",
    "    dn_drive = np.array(dn_drive)\n",
    "    physics_error, fly_flipped = False, False\n",
    "    iterator = trange if pbar else range\n",
    "    for _ in iterator(int(sim_duration / sim.timestep)):\n",
    "        action_hist.append(dn_drive)\n",
    "\n",
    "        try:\n",
    "            obs, reward, terminated, truncated, info = sim.step(dn_drive)\n",
    "        except PhysicsError:\n",
    "            print(\"Physics error detected!\")\n",
    "            physics_error = True\n",
    "            break\n",
    "\n",
    "        if enable_rendering:\n",
    "            rendered_img = sim.render()[0]\n",
    "\n",
    "        # Get necessary angles\n",
    "        quat = sim.physics.bind(sim.fly.thorax).xquat\n",
    "        quat_inv = transformations.quat_inv(quat)\n",
    "        roll, pitch, yaw = transformations.quat_to_euler(quat_inv, ordering=\"XYZ\")\n",
    "        info[\"roll\"], info[\"pitch\"], info[\"yaw\"] = roll, pitch, yaw\n",
    "\n",
    "        obs_hist.append(obs)\n",
    "        info_hist.append(info)\n",
    "\n",
    "        if info[\"flip\"]:\n",
    "            print(\"Flip detected!\")\n",
    "            break\n",
    "\n",
    "        # Live display\n",
    "        if enable_rendering and live_display and rendered_img is not None:\n",
    "            cv2.imshow(\"rendered_img\", rendered_img[:, :, ::-1])\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    # Save data if output_dir is provided\n",
    "    if output_dir is not None:\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if enable_rendering:\n",
    "            cam.save_video(output_dir / \"rendering.mp4\")\n",
    "        with open(output_dir / \"sim_data.pkl\", \"wb\") as f:\n",
    "            data = {\n",
    "                \"obs_hist\": obs_hist,\n",
    "                \"info_hist\": info_hist,\n",
    "                \"action_hist\": action_hist,\n",
    "                \"errors\": {\n",
    "                    \"fly_flipped\": fly_flipped,\n",
    "                    \"physics_error\": physics_error,\n",
    "                },\n",
    "            }\n",
    "            pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we will run a short simulation using the descending drive [1.0, 1.0] to walk straight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"outputs/head_stabilization/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_simulation(\n",
    "    gait=\"tripod\",\n",
    "    terrain=\"flat\",\n",
    "    spawn_xy=(0, 0),\n",
    "    dn_drive=(1, 1),\n",
    "    sim_duration=0.5,\n",
    "    enable_rendering=True,\n",
    "    live_display=False,\n",
    "    output_dir=output_dir / \"tripod_flat_train_set_1.00_1.00\",\n",
    "    pbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can plot the trajectory of the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(output_dir / \"tripod_flat_train_set_1.00_1.00/sim_data.pkl\", \"rb\") as f:\n",
    "    sim_data_flat = pickle.load(f)\n",
    "\n",
    "trajectory = np.array([obs[\"fly\"][0, :2] for obs in sim_data_flat[\"obs_hist\"]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 2), tight_layout=True)\n",
    "ax.plot(trajectory[:, 0], trajectory[:, 1], label=\"Trajectory\")\n",
    "ax.plot([0], [0], \"ko\", label=\"Origin\")\n",
    "ax.legend()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"x position (mm)\")\n",
    "ax.set_ylabel(\"y position (mm)\")\n",
    "fig.savefig(output_dir / \"head_stabilization_trajectory_sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the time series of the variables that we are interested in, namely:\n",
    "\n",
    "- **Joint angles** of all leg degrees of freedom (DoFs), 7 real values per leg per step\n",
    "- **Leg contact** mask, 1 Boolean value per leg per step\n",
    "- The appropriate neck **roll** needed to cancel out body rotation, 1 real value per step\n",
    "- The appropriate neck **pitch** needed to cancel out body rotation, 1 real value per step\n",
    "\n",
    "Note that we do not correct for rotation on the yaw axis. This is to avoid delineating unintended body oscillation the from intentional turning — a task outside the scope of this tutorial.\n",
    "\n",
    "To get the leg contacts, we will use a contact force threshold of 0.5 mN for the front legs, 1 mN for the middle legs, and 3 mN for the hind legs — as was the case in the path integration tutorial.\n",
    "\n",
    "To get the appropriate neck roll and pitch needed to cancel out body rotations, we will take the **quaternion** representing the thorax rotation, invert it, and convert it to **Euler angles**. Quaternions are a mathematical concept used to represent rotations in three dimensions. They avoid some of the pitfalls of other rotation representations, such as gimbal lock. However, quaternions are less intuitive to interpret and their elements do not directly correspond to the axes on the fly body. Therefore, we convert the inverted angles to Euler angles with more familiar axes of rotation (pitch, roll, yaw). More information about representation of 3D rotation can be found on [this Wikipedia article](https://en.wikipedia.org/wiki/Rotation_formalisms_in_three_dimensions).\n",
    "\n",
    "For simplicity of visualization, we will only plot the legs on the left side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "dofs_per_leg = [\n",
    "    \"ThC pitch\",\n",
    "    \"ThC roll\",\n",
    "    \"ThC yaw\",\n",
    "    \"CTr pitch\",\n",
    "    \"CTr roll\",\n",
    "    \"FTi pitch\",\n",
    "    \"TiTa pitch\",\n",
    "]\n",
    "contact_force_thr = np.array([0.5, 1.0, 3.0, 0.5, 1.0, 3.0])  # LF LM LH RF RM RH\n",
    "\n",
    "\n",
    "def visualize_trial_data(obs_hist, info_hist, output_path):\n",
    "    t_grid = np.arange(len(obs_hist)) * 1e-4\n",
    "\n",
    "    # Extract joint angles\n",
    "    joint_angles = np.array([obs[\"joints\"][0, :] for obs in obs_hist])\n",
    "\n",
    "    # Extract ground contact\n",
    "    contact_forces = np.array([obs[\"contact_forces\"] for obs in obs_hist])\n",
    "    # get magnitude from xyz vector:\n",
    "    contact_forces = np.linalg.norm(contact_forces, axis=2)\n",
    "    # sum over 6 segments per leg (contact sensing enabled for tibia and 5 tarsal segments):\n",
    "    contact_forces = contact_forces.reshape(-1, 6, 6).sum(axis=2)\n",
    "    contact_mask = contact_forces >= contact_force_thr\n",
    "\n",
    "    # Extract head rotation\n",
    "    roll = np.array([info[\"roll\"] for info in info_hist])\n",
    "    pitch = np.array([info[\"pitch\"] for info in info_hist])\n",
    "\n",
    "    # Visualize\n",
    "    fig, axs = plt.subplots(\n",
    "        6, 1, figsize=(6, 9), tight_layout=True, height_ratios=[3, 3, 3, 2, 3, 1]\n",
    "    )\n",
    "\n",
    "    # Legs\n",
    "    for i, leg in enumerate([\"Left front leg\", \"Left middle leg\", \"Left hind leg\"]):\n",
    "        ax = axs[i]\n",
    "        # Plot joint angles\n",
    "        for j, dof in enumerate(dofs_per_leg):\n",
    "            dof_idx = i * len(dofs_per_leg) + j\n",
    "            ax.plot(t_grid, np.rad2deg(joint_angles[:, dof_idx]), label=dof, lw=1)\n",
    "        ax.set_title(leg)\n",
    "        ax.set_ylabel(r\"Joint angle ($^\\circ$)\")\n",
    "        ax.set_ylim(-180, 180)\n",
    "        ax.set_yticks([-180, -90, 0, 90, 180])\n",
    "        # Plot ground contact\n",
    "        bool_ts = contact_mask[:, i]\n",
    "        diff_ts = np.diff(bool_ts.astype(int), prepend=0)\n",
    "        if bool_ts[0]:\n",
    "            diff_ts[0] = 1\n",
    "        if bool_ts[-1]:\n",
    "            diff_ts[-1] = -1\n",
    "        upedges = np.where(diff_ts == 1)[0]\n",
    "        downedges = np.where(diff_ts == -1)[0]\n",
    "        for up, down in zip(upedges, downedges):\n",
    "            ax.axvspan(\n",
    "                t_grid[up],\n",
    "                t_grid[down],\n",
    "                color=\"black\",\n",
    "                alpha=0.2,\n",
    "                lw=0,\n",
    "                label=\"Ground contact\",\n",
    "            )\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # Leg legends\n",
    "    legend_elements = []\n",
    "    for j, dof in enumerate(dofs_per_leg):\n",
    "        legend_elements.append(Line2D([0], [0], color=f\"C{j}\", lw=1, label=dof))\n",
    "    legend_elements.append(\n",
    "        Patch(color=\"black\", alpha=0.2, lw=0, label=\"Ground contact\")\n",
    "    )\n",
    "    axs[3].legend(\n",
    "        bbox_to_anchor=(0, 1.1, 1, 0.2),\n",
    "        handles=legend_elements,\n",
    "        loc=\"upper center\",\n",
    "        ncols=3,\n",
    "        mode=\"expand\",\n",
    "        frameon=False,\n",
    "    )\n",
    "    axs[3].axis(\"off\")\n",
    "\n",
    "    # Head movement\n",
    "    ax = axs[4]\n",
    "    ax.plot(t_grid, np.rad2deg(roll), label=\"Head roll\", lw=2, color=\"midnightblue\")\n",
    "    ax.plot(t_grid, np.rad2deg(pitch), label=\"Head pitch\", lw=2, color=\"saddlebrown\")\n",
    "    ax.set_title(\"Head movement\")\n",
    "    ax.set_ylabel(r\"Angle ($^\\circ$)\")\n",
    "    ax.set_ylim(-20, 20)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # Head legends\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color=f\"midnightblue\", lw=2, label=\"Roll\"),\n",
    "        Line2D([0], [0], color=f\"saddlebrown\", lw=2, label=\"Pitch\"),\n",
    "    ]\n",
    "    axs[5].legend(\n",
    "        bbox_to_anchor=(0, 1.4, 1, 0.2),\n",
    "        handles=legend_elements,\n",
    "        loc=\"upper center\",\n",
    "        ncols=2,\n",
    "        mode=\"expand\",\n",
    "        frameon=False,\n",
    "    )\n",
    "    axs[5].axis(\"off\")\n",
    "\n",
    "    fig.savefig(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_trial_data(\n",
    "    sim_data_flat[\"obs_hist\"],\n",
    "    sim_data_flat[\"info_hist\"],\n",
    "    output_dir / \"head_stabilization_flat_terrain_ts_sample.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that, after about 0.1 seconds of transient response, we can indeed see the gait cycles from the input variables.\n",
    "\n",
    "If we run another simulation over rugged terrain, the body oscillations appear more dramatic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    gait=\"tripod\",\n",
    "    terrain=\"blocks\",\n",
    "    spawn_xy=(0, 0),\n",
    "    dn_drive=(1, 1),\n",
    "    sim_duration=0.5,\n",
    "    enable_rendering=True,\n",
    "    live_display=False,\n",
    "    output_dir=output_dir / \"tripod_blocks_train_set_1.00_1.00\",\n",
    "    pbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir / \"tripod_blocks_train_set_1.00_1.00/sim_data.pkl\", \"rb\") as f:\n",
    "    sim_data_blocks = pickle.load(f)\n",
    "\n",
    "visualize_trial_data(\n",
    "    sim_data_blocks[\"obs_hist\"],\n",
    "    sim_data_blocks[\"info_hist\"],\n",
    "    output_dir / \"head_stabilization_blocks_terrain_ts_sample.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an internal model to control neck actuation\n",
    "\n",
    "In the previous section, we have extracted the ascending sensory signals and the target motor outputs that are the model's inputs and outputs. Now, we will train a multilayer perceptron (MLP) that predicts the appropriate neck actuation signals using this ascending mechanosensory information. We will split this task into three technical steps:\n",
    "\n",
    "1. Implementing a custom PyTorch dataset class to feed our data, through a dataloader, into the model\n",
    "2. Defining an MLP with three hidden layers\n",
    "3. Training the MLP using the data we have gathered and the data pipeline that we will have developed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a custom PyTorch dataset\n",
    "\n",
    "When training any machine learning or statistical model, it is often desired to normalize or standardize the input. We will start by implementing a `JointAngleScaler` class to do standardize joint angle data (subtract mean, divide by standard deviation). This class can be initialized in one of two ways:\n",
    "\n",
    "1. A `.from_data` method that calculates the mean and standard deviation from a given dataset.\n",
    "2. A `.from_params` method that uses given user-specified mean and and standard deviation.\n",
    "\n",
    "This way, we can compute the mean and standard deviation from one trial and use the same parameters on all datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointAngleScaler:\n",
    "    \"\"\"\n",
    "    A class for standardizing joint angles (i.e., using mean and standard\n",
    "    deviation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mean : np.ndarray\n",
    "        The mean values used for scaling.\n",
    "    std : np.ndarray\n",
    "        The standard deviation values used for scaling.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(cls, joint_angles: np.ndarray):\n",
    "        \"\"\"\n",
    "        Create a JointAngleScaler instance from joint angle data. The mean\n",
    "        and standard deviation values are calculated from the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        joint_angles : np.ndarray\n",
    "            The joint angle data. The shape should be (n_samples, n_joints)\n",
    "            where n_samples is, for example, the length of a time series of\n",
    "            joint angles.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        JointAngleScaler\n",
    "            A JointAngleScaler instance.\n",
    "        \"\"\"\n",
    "        scaler = cls()\n",
    "        scaler.mean = np.mean(joint_angles, axis=0)\n",
    "        scaler.std = np.std(joint_angles, axis=0)\n",
    "        return scaler\n",
    "\n",
    "    @classmethod\n",
    "    def from_params(cls, mean: np.ndarray, std: np.ndarray):\n",
    "        \"\"\"\n",
    "        Create a JointAngleScaler instance from predetermined mean and\n",
    "        standard deviation values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mean : np.ndarray\n",
    "            The mean values. The shape should be (n_joints,).\n",
    "        std : np.ndarray\n",
    "            The standard deviation values. The shape should be (n_joints,).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        JointAngleScaler\n",
    "            A JointAngleScaler instance.\n",
    "        \"\"\"\n",
    "        scaler = cls()\n",
    "        scaler.mean = mean\n",
    "        scaler.std = std\n",
    "        return scaler\n",
    "\n",
    "    def __call__(self, joint_angles: np.ndarray):\n",
    "        \"\"\"\n",
    "        Scale the given joint angles.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        joint_angles : np.ndarray\n",
    "            The joint angles to be scaled. The shape should be (n_samples,\n",
    "            n_joints) where n_samples is, for example, the length of a time\n",
    "            series of joint angles.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The scaled joint angles.\n",
    "        \"\"\"\n",
    "        return (joint_angles - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will construct a PyTorch dataset class. This class can be seen as an \"adapter\": on one side, it interfaces the specifics of our data (data structure, format, etc.); on the other side, it outputs what PyTorch models expect, so that the neural network can work with it. See [this tutorial from Pytorch](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for more details on the Dataset interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from typing import Optional, Callable\n",
    "\n",
    "\n",
    "class WalkingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for walking data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sim_data_file : Path\n",
    "        The path to the simulation data file.\n",
    "    contact_force_thr : tuple[float, float, float], optional\n",
    "        The threshold values for contact forces, by default (0.5, 1, 3).\n",
    "    joint_angle_scaler : Optional[Callable], optional\n",
    "        A callable object used to scale joint angles, by default None.\n",
    "    ignore_first_n : int, optional\n",
    "        The number of initial data points to ignore, by default 200.\n",
    "    joint_mask : Optional, optional\n",
    "        A mask to apply on joint angles, by default None.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    gait : str\n",
    "        The type of gait.\n",
    "    terrain : str\n",
    "        The type of terrain.\n",
    "    subset : str\n",
    "        The subset of the data, i.e., \"train\" or \"test\".\n",
    "    dn_drive : str\n",
    "        The DN drive used to generate the data.\n",
    "    contact_force_thr : np.ndarray\n",
    "        The threshold values for contact forces.\n",
    "    joint_angle_scaler : Callable\n",
    "        The callable object used to scale joint angles.\n",
    "    ignore_first_n : int\n",
    "        The number of initial data points to ignore.\n",
    "    joint_mask : Optional\n",
    "        The mask applied on joint angles. This is used to zero out certain\n",
    "        DoFs to evaluate which DoFs are likely more important for head\n",
    "        stabilization.\n",
    "    contains_fly_flip : bool\n",
    "        Indicates if the simulation data contains fly flip errors.\n",
    "    contains_physics_error : bool\n",
    "        Indicates if the simulation data contains physics errors.\n",
    "    roll_pitch_ts : np.ndarray\n",
    "        The optimal roll and pitch correction angles. The shape is\n",
    "        (n_samples, 2).\n",
    "    joint_angles : np.ndarray\n",
    "        The scaled joint angle time series. The shape is (n_samples,\n",
    "        n_joints).\n",
    "    contact_mask : np.ndarray\n",
    "        The contact force mask (i.e., 1 if leg touching the floor, 0\n",
    "        otherwise). The shape is (n_samples, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sim_data_file: Path,\n",
    "        contact_force_thr: tuple[float, float, float] = (0.5, 1, 3),\n",
    "        joint_angle_scaler: Optional[Callable] = None,\n",
    "        ignore_first_n: int = 200,\n",
    "        joint_mask=None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        trial_name = sim_data_file.parent.name\n",
    "        gait, terrain, subset, _, dn_left, dn_right = trial_name.split(\"_\")\n",
    "        self.gait = gait\n",
    "        self.terrain = terrain\n",
    "        self.subset = subset\n",
    "        self.dn_drive = f\"{dn_left}_{dn_right}\"\n",
    "        self.contact_force_thr = np.array([*contact_force_thr, *contact_force_thr])\n",
    "        self.joint_angle_scaler = joint_angle_scaler\n",
    "        self.ignore_first_n = ignore_first_n\n",
    "        self.joint_mask = joint_mask\n",
    "\n",
    "        with open(sim_data_file, \"rb\") as f:\n",
    "            sim_data = pickle.load(f)\n",
    "\n",
    "        self.contains_fly_flip = sim_data[\"errors\"][\"fly_flipped\"]\n",
    "        self.contains_physics_error = sim_data[\"errors\"][\"physics_error\"]\n",
    "\n",
    "        # Extract the roll and pitch angles\n",
    "        roll = np.array([info[\"roll\"] for info in sim_data[\"info_hist\"]])\n",
    "        pitch = np.array([info[\"pitch\"] for info in sim_data[\"info_hist\"]])\n",
    "        self.roll_pitch_ts = np.stack([roll, pitch], axis=1)\n",
    "        self.roll_pitch_ts = self.roll_pitch_ts[self.ignore_first_n :, :]\n",
    "\n",
    "        # Extract joint angles and scale them\n",
    "        joint_angles_raw = np.array(\n",
    "            [obs[\"joints\"][0, :] for obs in sim_data[\"obs_hist\"]]\n",
    "        )\n",
    "        if self.joint_angle_scaler is None:\n",
    "            self.joint_angle_scaler = JointAngleScaler.from_data(joint_angles_raw)\n",
    "        self.joint_angles = self.joint_angle_scaler(joint_angles_raw)\n",
    "        self.joint_angles = self.joint_angles[self.ignore_first_n :, :]\n",
    "\n",
    "        # Extract contact forces\n",
    "        contact_forces = np.array(\n",
    "            [obs[\"contact_forces\"] for obs in sim_data[\"obs_hist\"]]\n",
    "        )\n",
    "        contact_forces = np.linalg.norm(contact_forces, axis=2)  # magnitude\n",
    "        contact_forces = contact_forces.reshape(-1, 6, 6).sum(axis=2)  # sum per leg\n",
    "        self.contact_mask = (contact_forces >= self.contact_force_thr).astype(np.int16)\n",
    "        self.contact_mask = self.contact_mask[self.ignore_first_n :, :]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.roll_pitch_ts.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        joint_angles = self.joint_angles[idx].astype(np.float32, copy=True)\n",
    "        if self.joint_mask is not None:\n",
    "            joint_angles[~self.joint_mask] = 0\n",
    "        return {\n",
    "            \"roll_pitch\": self.roll_pitch_ts[idx].astype(np.float32),\n",
    "            \"joint_angles\": joint_angles,\n",
    "            \"contact_mask\": self.contact_mask[idx].astype(np.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the joint angle scaler and dataset classes using our trial simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_angles = np.array([obs[\"joints\"][0, :] for obs in sim_data_flat[\"obs_hist\"]])\n",
    "joint_scaler = JointAngleScaler.from_data(joint_angles)\n",
    "dataset = WalkingDataset(\n",
    "    sim_data_file=output_dir / \"tripod_flat_train_set_1.00_1.00/sim_data.pkl\",\n",
    "    joint_angle_scaler=joint_scaler,\n",
    "    ignore_first_n=200,\n",
    ")\n",
    "with open(output_dir / \"head_stabilization_joint_angle_scaler_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"mean\": joint_scaler.mean, \"std\": joint_scaler.std}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the joint angles for the left front leg again, but using the dataset as an iterator instead of the output returned by `run_simulation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid = np.arange(200, 200 + len(dataset)) * 1e-4\n",
    "joint_angles = np.array([entry[\"joint_angles\"] for entry in dataset])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "ax.axhline(0, color=\"black\", lw=1)\n",
    "ax.axhspan(-1, 1, color=\"black\", alpha=0.2, lw=0)\n",
    "for i, dof in enumerate(dofs_per_leg):\n",
    "    ax.plot(t_grid, joint_angles[:, i], label=dof, lw=1)\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "    loc=\"lower left\",\n",
    "    mode=\"expand\",\n",
    "    borderaxespad=0,\n",
    "    ncol=4,\n",
    ")\n",
    "ax.set_xlim(0, 0.5)\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Standardized joint angle (AU)\")\n",
    "fig.savefig(output_dir / \"head_stabilization_joint_angles_scaled.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the joint angles now share a mean of 0 (black line) and standard deviation of 1 (gray shade).\n",
    "\n",
    "We can further use the PyTorch dataloader to fetch data in batches. This is useful for training the MLP in the next step. As an example, we can create a dataset that gives us a shuffled batch of 32 samples at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "example_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in example_loader:\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key}\\tshape: {value.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an MLP\n",
    "\n",
    "Having implemented the data pipeline, we will now define the model itself. We will use [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/), a framework built on top of PyTorch that simplifies checkpointing (saving snapshots of model parameters during training), logging, etc.\n",
    "\n",
    "In brief, our `ThreeLayerMLP` class, implemented below, consists of the following:\n",
    "\n",
    "- An `__init__` method that creates three hidden layers and a `R2Score` object that calculates the $R^2$ score.\n",
    "- A `forward` method that implements the forward pass of the neural network — a process where we traverse layers in the network to calculate values of the output layer based on the input. In our case, we simply apply the three hidden layers sequentially, with a Rectified Linear Unit (ReLU) activation function at the end of the first two layers. Based on this method, PyTorch will automatically implement the backward pass — a process in gradient-based optimization algorithms where, after the forward pass, the gradients for parameters in all layers are traced, starting from the gradient of the loss on the outputs (i.e., last layer).\n",
    "- A `configure_optimizer` method that sets up the optimizer — in our case an [Adam optimizer](https://arxiv.org/abs/1412.6980) with a learning rate of 0.001.\n",
    "- A `training_step` method that defines the operation to be conducted for each training step (i.e. every time the model receives a new batch of training data). Here, we concatenate the joint angles and leg contact masks into a single input block, run the forward pass (we can simply call the module itself on in the input for this), and calculate the MSE loss. Then, we log the loss as *training loss* and return it. PyTorch Lightning will do the backpropagation for us.\n",
    "- A `validation_step` method that defines what the model should do every time a batch of validation data is received. Similar to `training_step`, we run the forward pass, but this time we calculate the $R^2$ scores in addition to the MSE loss. Lastly, we log the $R^2$ and MSE metrics accordingly.\n",
    "\n",
    "For more information on implementing a PyTorch Lightning module, see [this tutorial](https://lightning.ai/courses/deep-learning-fundamentals/overview-organizing-your-code-with-pytorch-lightning/5-2-training-a-multilayer-perceptron-using-the-lightning-trainer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as pl\n",
    "from torchmetrics.regression import R2Score\n",
    "\n",
    "\n",
    "pl.seed_everything(0, workers=True)\n",
    "\n",
    "\n",
    "class ThreeLayerMLP(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning module for a three-layer MLP that predicts the\n",
    "    head roll and pitch correction angles based on proprioception and\n",
    "    tactile information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        input_size = 42 + 6\n",
    "        hidden_size = 32\n",
    "        output_size = 2\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, output_size)\n",
    "        self.r2_score = R2Score()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The input tensor. The shape should be (n_samples, 42 + 6)\n",
    "            where 42 is the number of joint angles and 6 is the number of\n",
    "            contact masks.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Use the Adam optimizer.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step of the PyTorch Lightning module.\"\"\"\n",
    "        x = torch.concat([batch[\"joint_angles\"], batch[\"contact_mask\"]], dim=1)\n",
    "        y = batch[\"roll_pitch\"]\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step of the PyTorch Lightning module.\"\"\"\n",
    "        x = torch.concat([batch[\"joint_angles\"], batch[\"contact_mask\"]], dim=1)\n",
    "        y = batch[\"roll_pitch\"]\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        if y.shape[0] > 1:\n",
    "            r2_roll = self.r2_score(y_hat[:, 0], y[:, 0])\n",
    "            r2_pitch = self.r2_score(y_hat[:, 1], y[:, 1])\n",
    "        else:\n",
    "            r2_roll, r2_pitch = np.nan, np.nan\n",
    "        self.log(\"val_r2_roll\", r2_roll)\n",
    "        self.log(\"val_r2_pitch\", r2_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Having implemented the data pipeline and defined the model, we will now train the model. We have pre-generated 126 simulation trials, including 11 training trials and 10 testing trials with different descending drives, for each of the three gait patterns (tripod gait, tetrapod gait, and wave gait), and for flat and blocks terrain types. Of these, we exclude one simulation (wave gait, blocks terrain, test set, DN drives [0.58, 1.14]) because the fly flipped while walking. You can download this dataset by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. We are working with our IT team to set up a gateway to share these data publicly\n",
    "# in a secure manner. We aim to update this by the end of June, 2024. Please reach out\n",
    "# to us by email in the meantime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data_dir = (\n",
    "    #Path.home() / \"Data/flygym_demo_data/head_stabilization/random_exploration/\"\n",
    "    Path(\"/Users/stimpfli/Desktop/flygym/outputs/head_stabilization/random_exploration\")\n",
    ")\n",
    "\n",
    "if not simulation_data_dir.is_dir():\n",
    "    raise FileNotFoundError(\n",
    "        \"Pregenerated simulation data not found. Please download it from TODO.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"[OK] Pregenerated simulation data found. Ready to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a `WalkingDataset` object (implemented above) for each training trial and concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dataset_list = []\n",
    "for gait in [\"tripod\", \"tetrapod\", \"wave\"]:\n",
    "    for terrain in [\"flat\", \"blocks\"]:\n",
    "        paths = simulation_data_dir.glob(f\"{gait}_{terrain}_train_set_*\")\n",
    "        print(f\"Loading {gait} gait, {terrain} terrain...\")\n",
    "        dn_drives = [\"_\".join(p.name.split(\"_\")[-2:]) for p in paths]\n",
    "        for dn_drive in dn_drives:\n",
    "            sim = f\"{gait}_{terrain}_train_set_{dn_drive}\"\n",
    "            path = simulation_data_dir / f\"{sim}/sim_data.pkl\"\n",
    "            ds = WalkingDataset(path, joint_angle_scaler=joint_scaler)\n",
    "            ds.joint_mask = np.ones(42, dtype=bool)  # use all joints\n",
    "            dataset_list.append(ds)\n",
    "concat_train_set = ConcatDataset(dataset_list)\n",
    "\n",
    "print(f\"Training dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size is as expected: (3 gaits × 2 terrain types × 11 DN combinations) × (0.5 seconds of simulation / 0.0001 seconds per step – 200 transient steps excluded) = 976,800 samples in total.\n",
    "\n",
    "We will further divide the training set into the training set a validation set at a ratio of 4:1:\n",
    "\n",
    "- The training set is used to optimize the parameters of the model.\n",
    "- The validation set is used to check if the model has been overfitted.\n",
    "- The testing set is held out throughout the entire training procedure. It consists of trials simulated using a different set of descending drives and is only used to report the final out-of-sample performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(concat_train_set, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated above, we will create dataloaders for the training and validation sets to load the data in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, num_workers=4, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1028, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will set up a logger to keep track of the training progress, a checkpoint callback that saves snapshots of model parameters while training, and a trainer object to orchestrate the training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from shutil import rmtree\n",
    "\n",
    "log_dir = Path(output_dir / \"logs\")\n",
    "if log_dir.is_dir():\n",
    "    rmtree(log_dir)\n",
    "logger = CSVLogger(log_dir, name=\"demo_trial\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=output_dir / \"models/checkpoints\",\n",
    "    filename=\"%s-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,  # Save only the best checkpoint\n",
    "    mode=\"min\",  # `min` for minimizing the validation loss\n",
    ")\n",
    "model = ThreeLayerMLP()\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=10,\n",
    "    check_val_every_n_epoch=1,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the model. We will train the model for 10 epochs. On a machine with a NVIDIA GeForce RTX 3080 Ti GPU (2021), this takes about 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the model's performance on the training and validation sets changed over time. On the validation set, we will plot the loss and $R^2$ scores at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs = pd.read_csv(log_dir / \"demo_trial/version_0/metrics.csv\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 5), tight_layout=True, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "mask = np.isfinite(logs[\"train_loss\"])\n",
    "ax.plot(logs[\"step\"][mask], logs[\"train_loss\"][mask], label=\"Training loss\")\n",
    "mask = np.isfinite(logs[\"val_loss\"])\n",
    "ax.plot(logs[\"step\"][mask], logs[\"val_loss\"][mask], label=\"Validation loss\", marker=\"o\")\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"MSE loss\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(\n",
    "    logs[\"step\"][mask],\n",
    "    logs[\"val_r2_roll\"][mask],\n",
    "    color=\"midnightblue\",\n",
    "    label=\"Roll\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.plot(\n",
    "    logs[\"step\"][mask],\n",
    "    logs[\"val_r2_pitch\"][mask],\n",
    "    color=\"saddlebrown\",\n",
    "    label=\"Pitch\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"R² score\")\n",
    "\n",
    "fig.savefig(output_dir / \"head_stabilization_training_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satisfied with the performance, we now proceed to evaluate the model on the testing set and deploy it in closed loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model\n",
    "\n",
    "While the PyTorch module `ThreeLayerMLP` can give us predictions, it is not very lean: a number of training-related elements are exposed to the caller. For example, the `forward` method expects a _batch_ of data concatenated in a specific way, and PyTorch will try to load it on an accelerated hardware automatically if one is found. This is not ideal for _real time_ deployment — we will only get one input snapshot at a time and the data is small enough and the steps frequent enough that it not worth loading/unloading data to the GPU every step. Therefore, as a next step, we will write a wrapper that provides a minimal interface that simplifies making single-step predictions natively on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadStabilizationInferenceWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper for the head stabilization model to make predictions on\n",
    "    observations. Whereas data are collected in large tensors during\n",
    "    training, this class provides a \"flat\" interface for making predictions\n",
    "    one observation (i.e., time step) at a time. This is useful for\n",
    "    deploying the model in closed loop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: Path,\n",
    "        scaler_param_path: Path,\n",
    "        contact_force_thr: tuple[float, float, float] = (0.5, 1, 3),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_path : Path\n",
    "            The path to the trained model.\n",
    "        scaler_param_path : Path\n",
    "            The path to the pickle file containing scaler parameters.\n",
    "        contact_force_thr : tuple[float, float, float], optional\n",
    "            The threshold values for contact forces that are used to\n",
    "            determine the floor contact flags, by default (0.5, 1, 3).\n",
    "        \"\"\"\n",
    "        # Load scaler params\n",
    "        with open(scaler_param_path, \"rb\") as f:\n",
    "            scaler_params = pickle.load(f)\n",
    "        self.scaler_mean = scaler_params[\"mean\"]\n",
    "        self.scaler_std = scaler_params[\"std\"]\n",
    "\n",
    "        # Load model\n",
    "        # it's not worth moving data to the GPU, just run it on the CPU\n",
    "        self.model = ThreeLayerMLP.load_from_checkpoint(\n",
    "            model_path, map_location=torch.device(\"cpu\")\n",
    "        )\n",
    "        self.contact_force_thr = np.array([*contact_force_thr, *contact_force_thr])\n",
    "\n",
    "    def __call__(\n",
    "        self, joint_angles: np.ndarray, contact_forces: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Make a prediction given joint angles and contact forces. This is\n",
    "        a light wrapper around the model's forward method and works without\n",
    "        batching.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        joint_angles : np.ndarray\n",
    "            The joint angles. The shape should be (n_joints,).\n",
    "        contact_forces : np.ndarray\n",
    "            The contact forces. The shape should be (n_legs * n_segments).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The predicted roll and pitch angles. The shape is (2,).\n",
    "        \"\"\"\n",
    "        joint_angles = (joint_angles - self.scaler_mean) / self.scaler_std\n",
    "        contact_forces = np.linalg.norm(contact_forces, axis=1)\n",
    "        contact_forces = contact_forces.reshape(6, 6).sum(axis=1)\n",
    "        contact_mask = contact_forces >= self.contact_force_thr\n",
    "        x = np.concatenate([joint_angles, contact_mask], dtype=np.float32)\n",
    "        input_tensor = torch.tensor(x[None, :], device=torch.device(\"cpu\"))\n",
    "        output_tensor = self.model(input_tensor)\n",
    "        return output_tensor.detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the model from the saved checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = HeadStabilizationInferenceWrapper(\n",
    "    model_path=checkpoint_callback.best_model_path,\n",
    "    scaler_param_path=output_dir / \"head_stabilization_joint_angle_scaler_params.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the head stabilization model in closed loop, we will write a `run_simulation_closed_loop` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.arena import BaseArena\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "\n",
    "def run_simulation_closed_loop(\n",
    "    arena: BaseArena,\n",
    "    run_time: float = 0.5,\n",
    "    head_stabilization_model: Optional[HeadStabilizationInferenceWrapper] = None,\n",
    "):\n",
    "    fly = Fly(\n",
    "        contact_sensor_placements=contact_sensor_placements,\n",
    "        vision_refresh_rate=500,\n",
    "        neck_kp=500,\n",
    "        head_stabilization_model=head_stabilization_model,\n",
    "    )\n",
    "    sim = HybridTurningController(fly=fly, arena=arena)\n",
    "    sim.reset(seed=0)\n",
    "\n",
    "    # These are updated at every time step and are used for generating\n",
    "    # statistics and plots (except vision_all, which is updated every\n",
    "    # time step where the visual input is updated. Visual updates are less\n",
    "    # frequent than physics steps).\n",
    "    head_rotation_hist = []\n",
    "    thorax_rotation_hist = []\n",
    "    neck_actuation_pred_hist = []  # model-predicted neck actuation\n",
    "    neck_actuation_true_hist = []  # ideal neck actuation\n",
    "\n",
    "    thorax_body = fly.model.find(\"body\", \"Thorax\")\n",
    "    head_body = fly.model.find(\"body\", \"Head\")\n",
    "\n",
    "    # Main simulation loop\n",
    "    for i in trange(int(run_time / sim.timestep)):\n",
    "        try:\n",
    "            obs, _, _, _, info = sim.step(action=np.array([1, 1]))\n",
    "        except PhysicsError:\n",
    "            print(\"Physics error, ending simulation early\")\n",
    "            break\n",
    "\n",
    "        # Record neck actuation for stats at the end of the simulation\n",
    "        if head_stabilization_model is not None:\n",
    "            neck_actuation_pred_hist.append(info[\"neck_actuation\"])\n",
    "        quat = sim.physics.bind(fly.thorax).xquat\n",
    "        quat_inv = transformations.quat_inv(quat)\n",
    "        roll, pitch, _ = transformations.quat_to_euler(quat_inv, ordering=\"XYZ\")\n",
    "        neck_actuation_true_hist.append(np.array([roll, pitch]))\n",
    "\n",
    "        # Record head and thorax orientation\n",
    "        thorax_rotation_quat = sim.physics.bind(thorax_body).xquat\n",
    "        thorax_roll, thorax_pitch, _ = transformations.quat_to_euler(\n",
    "            thorax_rotation_quat, ordering=\"XYZ\"\n",
    "        )\n",
    "        thorax_rotation_hist.append([thorax_roll, thorax_pitch])\n",
    "        head_rotation_quat = sim.physics.bind(head_body).xquat\n",
    "        head_roll, head_pitch, _ = transformations.quat_to_euler(\n",
    "            head_rotation_quat, ordering=\"XYZ\"\n",
    "        )\n",
    "        head_rotation_hist.append([head_roll, head_pitch])\n",
    "\n",
    "    # Generate performance stats on head stabilization\n",
    "    if head_stabilization_model is not None:\n",
    "        neck_actuation_true_hist = np.array(neck_actuation_true_hist)\n",
    "        neck_actuation_pred_hist = np.array(neck_actuation_pred_hist)\n",
    "        r2_scores = {\n",
    "            # exclude the first 200 frames (transient response)\n",
    "            \"roll\": r2_score(\n",
    "                neck_actuation_true_hist[200:, 0], neck_actuation_pred_hist[200:, 0]\n",
    "            ),\n",
    "            \"pitch\": r2_score(\n",
    "                neck_actuation_true_hist[200:, 1], neck_actuation_pred_hist[200:, 1]\n",
    "            ),\n",
    "        }\n",
    "    else:\n",
    "        r2_scores = None\n",
    "        neck_actuation_true_hist = np.array(neck_actuation_true_hist)\n",
    "        neck_actuation_pred_hist = np.zeros_like(neck_actuation_true_hist)\n",
    "\n",
    "    return {\n",
    "        \"sim\": sim,\n",
    "        \"neck_true\": neck_actuation_true_hist,\n",
    "        \"neck_pred\": neck_actuation_pred_hist,\n",
    "        \"r2_scores\": r2_scores,\n",
    "        \"head_rotation_hist\": np.array(head_rotation_hist),\n",
    "        \"thorax_rotation_hist\": np.array(thorax_rotation_hist),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the model-predicted neck actuation signals, we have simply passed the model as the `head_stabilization_model` parameter to the `Fly` object. Under the hood, the `Fly` object initializes actuators for the neck roll and pitch DoFs upon `__init__`. Then, at each simulation step, the `Fly` class runs the `head_stabilization_model` and actuates the appropriate DoFs in addition to the user-specified actions. In code, this is implemented as follows:\n",
    "```python\n",
    "class Fly:\n",
    "    def __init__(... head_stabilization_model ...):\n",
    "        ...\n",
    "        \n",
    "        # Check neck actuation if head stabilization is enabled\n",
    "        if head_stabilization_model is not None:\n",
    "            if \"joint_Head_yaw\" in actuated_joints or \"joint_Head\" in actuated_joints:\n",
    "                raise ValueError(\n",
    "                    \"The head joints are actuated by a preset algorithm. \"\n",
    "                    \"However, the head joints are already included in the \"\n",
    "                    \"provided Fly instance. Please remove the head joints from \"\n",
    "                    \"the list of actuated joints.\"\n",
    "                )\n",
    "            self._last_neck_actuation = None  # tracked only for head stabilization\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        self.actuated_joints = actuated_joints\n",
    "        self.head_stabilization_model = head_stabilization_model\n",
    "        \n",
    "        ...\n",
    "\n",
    "        if self.head_stabilization_model is not None:\n",
    "            self.neck_actuators = [\n",
    "                self.model.actuator.add(\n",
    "                    self.control,\n",
    "                    name=f\"actuator_position_{joint}\",\n",
    "                    joint=joint,\n",
    "                    kp=neck_kp,\n",
    "                    ctrlrange=\"-1000000 1000000\",\n",
    "                    forcelimited=False,\n",
    "                )\n",
    "                for joint in [\"joint_Head_yaw\", \"joint_Head\"]\n",
    "            ]\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    def pre_step(self, action, sim):\n",
    "        joint_action = action[\"joints\"]\n",
    "\n",
    "        # estimate necessary neck actuation signals for head stabilization\n",
    "        if self.head_stabilization_model is not None:\n",
    "            if self._last_observation is not None:\n",
    "                leg_joint_angles = self._last_observation[\"joints\"][0, :]\n",
    "                leg_contact_forces = self._last_observation[\"contact_forces\"]\n",
    "                neck_actuation = self.head_stabilization_model(\n",
    "                    leg_joint_angles, leg_contact_forces\n",
    "                )\n",
    "            else:\n",
    "                neck_actuation = np.zeros(2)\n",
    "            joint_action = np.concatenate((joint_action, neck_actuation))\n",
    "            self._last_neck_actuation = neck_actuation\n",
    "            physics.bind(self.actuators + self.neck_actuators).ctrl = joint_action\n",
    "    \n",
    "    def post_step(self, sim):\n",
    "        obs, reward, terminated, truncated, info = ...\n",
    "\n",
    "        ...\n",
    "\n",
    "        if self.head_stabilization_model is not None:\n",
    "            # this is tracked to decide neck actuation for the next step\n",
    "            info[\"neck_actuation\"] = self._last_neck_actuation\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "class Simulation:\n",
    "    ...\n",
    "\n",
    "    def step(self, action):\n",
    "        ...\n",
    "        self.fly.pre_step(action, self)\n",
    "        obs, reward, terminated, truncated, info = self.fly.post_step()\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "```\n",
    "\n",
    "Now, we can run the simulation over flat and blocks terrain again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena = FlatTerrain()\n",
    "sim_data_flat = run_simulation_closed_loop(\n",
    "    arena=arena, run_time=1, head_stabilization_model=model_wrapper\n",
    ")\n",
    "\n",
    "arena = BlocksTerrain(height_range=(0.2, 0.2))\n",
    "sim_data_blocks = run_simulation_closed_loop(\n",
    "    arena=arena, run_time=1, head_stabilization_model=model_wrapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R² scores over flat terrain: {sim_data_flat['r2_scores']}\")\n",
    "print(f\"R² scores over blocks terrain: {sim_data_blocks['r2_scores']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, we can plot the time series of the model-predicted neck actuation signals and the ideal neck actuation signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(6, 5), tight_layout=True, sharex=True)\n",
    "color_config = {\n",
    "    \"roll\": (\"royalblue\", \"midnightblue\"),\n",
    "    \"pitch\": (\"peru\", \"saddlebrown\"),\n",
    "}\n",
    "\n",
    "for ax, terrain, data in zip(axs, [\"Flat\", \"Blocks\"], [sim_data_flat, sim_data_blocks]):\n",
    "    t_grid = np.arange(len(data[\"neck_true\"])) * 1e-4\n",
    "    for i, dof in enumerate([\"roll\", \"pitch\"]):\n",
    "        ax.plot(\n",
    "            t_grid,\n",
    "            np.rad2deg(data[\"neck_true\"][:, i]),\n",
    "            label=f\"Optimal {dof}\",\n",
    "            linestyle=\"--\",\n",
    "            color=color_config[dof][0],\n",
    "        )\n",
    "        ax.plot(\n",
    "            t_grid,\n",
    "            np.rad2deg(data[\"neck_pred\"][:, i]),\n",
    "            label=f\"Optimal {dof}\",\n",
    "            color=color_config[dof][1],\n",
    "        )\n",
    "    ax.set_title(f\"{terrain} terrain\")\n",
    "    ax.set_ylabel(r\"Target angle ($^\\circ$)\")\n",
    "    ax.set_ylim(-20, 20)\n",
    "    if terrain == \"Flat\":\n",
    "        ax.legend(ncols=2)\n",
    "    if terrain == \"Blocks\":\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "fig.savefig(output_dir / \"head_stabilization_neck_actuation_sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can plot the roll and pitch of the head compared to the thorax over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    2, 2, figsize=(8, 5), tight_layout=True, sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "for i, (terrain, data) in enumerate(\n",
    "    zip([\"Flat\", \"Blocks\"], [sim_data_flat, sim_data_blocks])\n",
    "):\n",
    "    for j, dof in enumerate([\"roll\", \"pitch\"]):\n",
    "        ax = axs[j, i]\n",
    "        ax.axhline(0, color=\"black\", lw=1)\n",
    "        ax.plot(\n",
    "            t_grid,\n",
    "            np.rad2deg(data[\"head_rotation_hist\"][:, j]),\n",
    "            label=\"Head\",\n",
    "            color=\"tab:red\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            t_grid,\n",
    "            np.rad2deg(data[\"thorax_rotation_hist\"][:, j]),\n",
    "            label=\"Thorax\",\n",
    "            color=\"tab:blue\",\n",
    "        )\n",
    "        ax.set_ylim(-15, 15)\n",
    "        if i == 0 and j == 0:\n",
    "            ax.legend()\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(rf\"{dof.capitalize()} angle ($^\\circ$)\")\n",
    "        if j == 0:\n",
    "            ax.set_title(f\"{terrain} terrain\")\n",
    "        if j == 1:\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "fig.savefig(output_dir / \"head_stabilization_head_vs_thorax.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the rotation of the head has a lower magnitude than that of the body, even over complex terrain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
